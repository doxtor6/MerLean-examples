\documentclass[11pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{braket}
\usepackage{dsfont}
\usepackage{enumitem}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}

% Theorem environments with shared counter for formalization order
\newtheorem{formalstatement}{Statement}
\newtheorem*{theorem*}{Theorem}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{corollary*}{Corollary}
\newtheorem*{proposition*}{Proposition}
\theoremstyle{definition}
\newtheorem*{definition*}{Definition}
\newtheorem*{remark*}{Remark}
\newtheorem*{preliminary*}{Preliminary}

% Common math commands
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\id}{\mathds{1}}

\title{Extracted Formal Statements\\[0.5em]\large For LEAN 4 + Mathlib Formalization}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
This document contains 47 formal statements extracted from the source paper,
ordered by \textbf{formalization dependency} (statements appear after their dependencies).
Each statement is numbered in the order it should be formalized.
\end{abstract}

\tableofcontents
\newpage

\section{Formal Statements (in Formalization Order)}

\subsection{Rem_1: StabilizerCodeConvention}
\label{Rem_1}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 1/47

\begin{remark*}[StabilizerCodeConvention]
Throughout this work, we consider an $[[n,k,d]]$ quantum low-density parity-check (qLDPC) stabilizer code on $n$ physical qubits, encoding $k$ logical qubits with distance $d$. The code is specified by a set of stabilizer checks $\{s_i\}$. A logical operator $L$ is a Pauli operator that commutes with all stabilizers but is not itself a stabilizer. By choosing an appropriate single-qubit basis for each physical qubit, we ensure that the logical operator $L$ being measured is a product of Pauli-$X$ matrices: $L = \prod_{v \in \text{supp}(L)} X_v$, where $\text{supp}(L)$ denotes the set of qubits on which $L$ acts non-trivially.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_2: GraphConvention}
\label{Rem_2}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 2/47

\begin{remark*}[GraphConvention]
Given a connected graph $G = (V_G, E_G)$ with vertex set $V_G$ and edge set $E_G$, we identify the vertices of $G$ with the qubits in the support of the logical operator $L$. For each edge $e \in E_G$, we introduce an auxiliary 'gauge qubit' initialized in the state $|0\rangle_e$. The graph $G$ may also include additional 'dummy vertices' beyond the qubits in the support of $L$. For each dummy vertex $v$, we add an auxiliary qubit initialized in the $|+\rangle$ state and gauge the operator $L \cdot X_v$. These dummy vertices have no effect on the gauging measurement outcome since measuring $X_v$ on a $|+\rangle$ state always returns $+1$.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_3: BinaryVectorNotation}
\label{Rem_3}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 3/47

\begin{remark*}[BinaryVectorNotation]
Throughout this work, we abuse notation by identifying a subset of vertices, edges, or cycles with its characteristic binary vector over $\mathbb{Z}_2 = \mathbb{F}_2$. For a set $S$ of vertices/edges/cycles, the corresponding binary vector has a 1 in position $i$ if and only if element $i$ belongs to $S$. Addition of binary vectors corresponds to symmetric difference of sets. This identification allows us to use linear algebra over $\mathbb{Z}_2$ to reason about graph-theoretic properties.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_4: ZTypeSupportConvention}
\label{Rem_4}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 4/47

\begin{remark*}[ZTypeSupportConvention]
For a Pauli operator $P$, the **$Z$-type support** of $P$, denoted $\mathcal{S}_Z$, is the set of qubits on which $P$ acts via $Y$ or $Z$ operators. Similarly, the **$X$-type support**, denoted $\mathcal{S}_X$, is the set of qubits on which $P$ acts via $X$ or $Y$ operators. A Pauli operator $P$ can be written as $P = i^{\sigma} \prod_{v \in \mathcal{S}_X} X_v \prod_{v \in \mathcal{S}_Z} Z_v$ for some phase $\sigma \in \{0,1,2,3\}$. If $P$ commutes with an $X$-type logical operator $L = \prod_v X_v$, then $|\mathcal{S}_Z| \equiv 0 \pmod{2}$ (the $Z$-type support has even cardinality).
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_5: CheegerConstantDefinition}
\label{Rem_5}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 5/47

\begin{remark*}[CheegerConstantDefinition]
For a graph $G = (V, E)$, the **Cheeger constant** (also called isoperimetric number or edge expansion) is defined as $h(G) = \min_{S \subseteq V, 0 < |S| \leq |V|/2} \frac{|\partial S|}{|S|}$, where $\partial S$ is the edge boundary of $S$, i.e., the set of edges with exactly one endpoint in $S$. A graph is called an **expander** if $h(G) \geq c$ for some constant $c > 0$. In this work, we require $h(G) \geq 1$ to ensure that the deformed code preserves the distance of the original code.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_6: CircuitImplementation}
\label{Rem_6}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 6/47

\noindent\textbf{Dependencies:} \hyperref[Rem_2]{Rem_2}

\begin{remark*}[CircuitImplementation]
The gauging procedure can be implemented by a quantum circuit with no additional ancilla qubits beyond the edge qubits. After initializing the edge qubits in $|0\rangle$, perform the entangling circuit $\prod_v \prod_{e \ni v} CX_{v \to e}$ where $CX_{v \to e}$ is a controlled-$X$ gate with control qubit $v$ and target qubit $e$. Next, projectively measure $X_v$ on all vertices $v \in G$ and keep the post-measurement state. Then repeat the same entangling circuit $\prod_v \prod_{e \ni v} CX_{v \to e}$. Finally, measure $Z_e$ on all edge qubits and discard them.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_1: BoundaryCoboundaryMaps}
\label{Def_1}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 7/47

\noindent\textbf{Dependencies:} \hyperref[Rem_3]{Rem_3}

\begin{definition*}[BoundaryCoboundaryMaps]
Let $G = (V, E)$ be a graph with a chosen collection $\mathcal{C}$ of cycles. We define the following $\mathbb{Z}_2$-linear maps using binary vector representations:

**Boundary map $\partial: \mathbb{Z}_2^{|E|} \to \mathbb{Z}_2^{|V|}$**: For a single edge $e = \{v, v'\}$, define $\partial e = v + v'$ (the binary vector with 1s at positions $v$ and $v'$). Extend linearly to edge-sets: $\partial(\sum_i e_i) = \sum_i \partial e_i$. Equivalently, $\partial$ is the incidence matrix of $G$ over $\mathbb{Z}_2$.

**Coboundary map $\delta: \mathbb{Z}_2^{|V|} \to \mathbb{Z}_2^{|E|}$**: Define $\delta = \partial^T$ (transpose of $\partial$). For a single vertex $v$, we have $\delta v = \sum_{e \ni v} e$ (the binary vector of all edges incident to $v$).

**Second boundary map $\partial_2: \mathbb{Z}_2^{|\mathcal{C}|} \to \mathbb{Z}_2^{|E|}$**: For a single cycle $c$, define $\partial_2 c = \sum_{e \in c} e$ (the binary vector of edges in $c$). Extend linearly.

**Second coboundary map $\delta_2: \mathbb{Z}_2^{|E|} \to \mathbb{Z}_2^{|\mathcal{C}|}$**: Define $\delta_2 = \partial_2^T$. For a single edge $e$, we have $\delta_2 e = \sum_{c \ni e} c$ (the binary vector of cycles containing $e$).
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_7: ExactnessOfBoundaryCoboundary}
\label{Rem_7}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 8/47

\noindent\textbf{Dependencies:} \hyperref[Def_1]{Def_1}

\begin{remark*}[ExactnessOfBoundaryCoboundary]
When a generating set of cycles for graph $G$ is chosen, the maps $\partial_2$ (boundary from cycles to edges) and $\partial$ (boundary from edges to vertices) form an exact sequence in the sense that $\text{im}(\partial_2) = \ker(\partial)$. That is, the image of $\partial_2$ equals the kernel of $\partial$: an edge-set is the boundary of some cycle-set if and only if it has zero boundary (i.e., every vertex has even degree in the edge-set). Similarly, the coboundary maps $\delta$ and $\delta_2$ form an exact sequence: $\ker(\delta_2) = \text{im}(\delta)$. Note that $\delta$ has a nontrivial kernel: $\ker(\delta) = \{\mathbf{0}, \mathbf{1}\}$ where $\mathbf{1}$ is the all-ones vector (corresponding to the full vertex set), since every edge has exactly two endpoints.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_8: DesiderataForG}
\label{Rem_8}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 9/47

\noindent\textbf{Dependencies:} \hyperref[Rem_5]{Rem_5}

\begin{remark*}[DesiderataForG]
When choosing the graph $G$ for the gauging measurement procedure, three desiderata guide the selection to achieve constant qubit overhead and maintain fault tolerance:

1. **Short paths**: $G$ should contain a constant-length edge-path between any pair of vertices that are in the $Z$-type support of some check from the original code. This ensures deformed checks have bounded weight.

2. **Sufficient expansion**: The Cheeger constant should satisfy $h(G) \geq 1$. This ensures the deformed code distance is at least as large as the original code distance.

3. **Low-weight cycles**: There should be a generating set of cycles for $G$ where each cycle has weight at most some constant. This ensures the $B_p$ flux operators have bounded weight.

When such a graph is found, the gauging measurement procedure has constant qubit overhead.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_9: WorstCaseGraphConstruction}
\label{Rem_9}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 10/47

\noindent\textbf{Dependencies:} \hyperref[Rem_8]{Rem_8}

\begin{remark*}[WorstCaseGraphConstruction]
A graph $G$ satisfying the desiderata in Rem_8 can be constructed with $O(W \log^2 W)$ qubit overhead, where $W = |\text{supp}(L)|$ is the weight of the logical operator being measured. The construction proceeds in three steps:

**Step 1 (Perfect matching):** For each original code check that overlaps the target logical $L$, pick a $\mathbb{Z}_2$-perfect-matching of the vertices in the $Z$-type support of that check. Add an edge to $G$ for each pair of matched vertices. This ensures short paths between vertices in the $Z$-type support of each check.

**Step 2 (Expansion):** Add edges to $G$ until $h(G) \geq 1$. This can be done by randomly adding edges while preserving constant degree, or by overlaying an existing constant-degree expander graph. Let $G_0$ denote the graph constructed so far.

**Step 3 (Cycle sparsification):** Add $R$ additional layers that are copies of $G_0$ on dummy vertices, connected sequentially back to the original vertices. Add edges within each layer to cellulate (triangulate) cycles and reduce the cycle-degree. The Freedman-Hastings decongestion lemma establishes that $R = O(\log^2 W)$ layers suffice to achieve constant cycle-degree for any constant-degree graph with $W$ vertices.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_10: Parallelization}
\label{Rem_10}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 11/47

\begin{remark*}[Parallelization]
The gauging measurement can be applied to multiple logical operators in parallel, provided that:

1. **Commutativity**: No pair of logical operators being measured simultaneously act on a common qubit via different non-trivial Pauli operators (e.g., one acts by $X$ and another by $Z$ on the same qubit).

2. **Bounded overlap**: To maintain an LDPC code during code deformation, only a constant number of logical operators being measured share support on any single qubit.

For codes supporting many disjoint logical representatives, this offers highly parallelized logical gates. Additionally, one can trade space overhead for time overhead by performing $2m-1$ measurements of equivalent logical operators in parallel for $d/m$ rounds and taking a majority vote to determine the classical outcome.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_2: GaussLawOperators}
\label{Def_2}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 12/47

\noindent\textbf{Dependencies:} \hyperref[Rem_1]{Rem_1}, \hyperref[Rem_2]{Rem_2}

\begin{definition*}[GaussLawOperators]
Given a connected graph $G = (V_G, E_G)$ whose vertices are identified with the qubits in the support of a logical operator $L = \prod_{v \in V_G} X_v$, the **Gauss's law operators** are the set $\mathcal{A} = \{A_v\}_{v \in V_G}$ where:
$$A_v = X_v \prod_{e \ni v} X_e$$
Here $X_v$ is the Pauli-$X$ operator on the vertex qubit $v$, and $X_e$ is the Pauli-$X$ operator on the edge qubit $e$. The product $\prod_{e \ni v}$ is over all edges incident to vertex $v$.

The Gauss's law operators satisfy:
1. Each $A_v$ is Hermitian with eigenvalues $\pm 1$.
2. All $A_v$ mutually commute: $[A_v, A_{v'}] = 0$ for all $v, v' \in V_G$.
3. $\prod_{v \in V_G} A_v = L \cdot \prod_{e \in E_G} X_e^{2} = L$ (since $X_e^2 = I$).

This last property is the key to the gauging measurement: measuring all $A_v$ and multiplying the outcomes yields the eigenvalue of $L$.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_3: FluxOperators}
\label{Def_3}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 13/47

\noindent\textbf{Dependencies:} \hyperref[Def_2]{Def_2}

\begin{definition*}[FluxOperators]
Given a connected graph $G = (V_G, E_G)$ with a generating set of cycles $\{p\}_C$ (where $C = |E_G| - |V_G| + 1$ is the number of independent cycles by Euler's formula for connected graphs), the **flux operators** are the set $\mathcal{B} = \{B_p\}_{p \in C}$ where:
$$B_p = \prod_{e \in p} Z_e$$
Here $Z_e$ is the Pauli-$Z$ operator on the edge qubit $e$, and the product is over all edges $e$ that belong to cycle $p$.

The flux operators arise from the initial state $|0\rangle^{\otimes E_G}$ of the edge qubits:
1. Initially, $Z_e |0\rangle_e = |0\rangle_e$ for each edge, so each $Z_e$ is a stabilizer.
2. After measuring the Gauss's law operators $A_v$ (which involve $X_e$ terms), individual $Z_e$ operators are no longer stabilizers.
3. However, products $B_p = \prod_{e \in p} Z_e$ over cycles remain stabilizers because they commute with all $A_v$: $[B_p, A_v] = 0$ for all $p, v$.

To verify: $B_p$ and $A_v$ commute because the number of edges in cycle $p$ incident to vertex $v$ is always even (either 0 or 2), so the number of anticommuting $X_e$-$Z_e$ pairs is even.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_4: DeformedOperator}
\label{Def_4}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 14/47

\noindent\textbf{Dependencies:} \hyperref[Rem_4]{Rem_4}, \hyperref[Def_1]{Def_1}

\begin{definition*}[DeformedOperator]
Let $P$ be a Pauli operator that commutes with the logical operator $L = \prod_{v \in V_G} X_v$. Write $P = i^{\sigma} \prod_{v \in \mathcal{S}_X} X_v \prod_{v \in \mathcal{S}_Z} Z_v$ where $\mathcal{S}_X$ is the $X$-type support and $\mathcal{S}_Z$ is the $Z$-type support of $P$. Since $P$ commutes with $L$, we have $|\mathcal{S}_Z| \equiv 0 \pmod{2}$.

The **deformed operator** $\tilde{P}$ is defined as:
$$\tilde{P} = P \prod_{e \in \gamma} Z_e$$
where $\gamma$ is an edge-path in $G$ satisfying $\partial \gamma = \mathcal{S}_Z \cap V_G$ (i.e., the boundary of the edge-set $\gamma$ equals the $Z$-type support of $P$ restricted to the vertices of $G$). Such a path $\gamma$ exists because $|\mathcal{S}_Z \cap V_G|$ is even.

Convention: We typically choose $\gamma$ to be a minimum-weight path (shortest collection of edges) satisfying the boundary condition.

Note: If $P$ does not commute with $L$, then $|\mathcal{S}_Z \cap V_G|$ is odd, no valid path $\gamma$ exists, and $P$ has no well-defined deformed version.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_5: DeformedCheck}
\label{Def_5}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 15/47

\noindent\textbf{Dependencies:} \hyperref[Def_4]{Def_4}

\begin{definition*}[DeformedCheck]
Let $s_j$ be a stabilizer check from the original code, written as $s_j = i^{\sigma} \prod_{v \in \mathcal{S}_X} X_v \prod_{v \in \mathcal{S}_Z} Z_v$. The **deformed check** $\tilde{s}_j$ is the deformed version of $s_j$:
$$\tilde{s}_j = s_j \prod_{e \in \gamma} Z_e$$
where $\gamma$ is an edge-path in $G$ satisfying $\partial \gamma = \mathcal{S}_Z \cap V_G$.

The original stabilizer checks are partitioned into two sets:
- **Set $\mathcal{C}$**: Checks with no $Z$-type support on $V_G$ (i.e., $\mathcal{S}_Z \cap V_G = \emptyset$). For these checks, $\tilde{s}_j = s_j$ (no deformation needed).
- **Set $\mathcal{S}$**: Checks with nontrivial $Z$-type support on $V_G$. These checks are genuinely deformed by the gauging procedure.

The deformed checks $\tilde{s}_j$ are well-defined because all original stabilizers commute with $L$, so $|\mathcal{S}_Z \cap V_G|$ is always even and a valid path $\gamma$ always exists.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_6: CycleSparsifiedGraph}
\label{Def_6}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 16/47

\noindent\textbf{Dependencies:} \hyperref[Def_1]{Def_1}

\begin{definition*}[CycleSparsifiedGraph]
Given a graph $G$ and a constant $c$ called the **cycle-degree bound**, a **cycle-sparsification** of $G$ is a new graph $\bar{\bar{G}}$ constructed as follows:

**Layer structure**: Build $R+1$ copies of $G$, labeled as layers $0, 1, 2, \ldots, R$. Layer 0 corresponds to the original graph $G$; layers $1, \ldots, R$ are copies on dummy vertices.

**Inter-layer edges**: Connect each vertex $v$ in layer $i$ to its copy in layer $i+1$ by an edge, for all $i = 0, \ldots, R-1$.

**Cellulation edges**: For each cycle in a chosen generating set of cycles for $G$, in exactly one layer, add edges that triangulate (cellulate) the cycle. The triangulation of a cycle $v_1 \to v_2 \to \cdots \to v_N \to v_1$ adds edges: $\{(v_1, v_{N-1}), (v_{N-1}, v_2), (v_2, v_{N-2}), (v_{N-2}, v_3), \ldots\}$ forming a sequence of triangles.

**Cycle-degree constraint**: The assignment of cycles to layers must ensure that in the resulting graph $\bar{\bar{G}}$, every edge participates in at most $c$ cycles from the chosen generating set.

Let $R_G^c$ denote the minimum number of layers required to achieve cycle-degree at most $c$. The **Freedman-Hastings decongestion lemma** establishes that $R_G^c = O(\log^2 |V_G|)$ for any constant-degree graph $G$.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_7: SpaceAndTimeFaults}
\label{Def_7}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 17/47

\begin{definition*}[SpaceAndTimeFaults]
In the context of fault-tolerant implementation of the gauging measurement procedure:

**Space-fault**: A Pauli error operator (single-qubit $X$, $Y$, or $Z$ error) that occurs on some qubit at some time during the procedure. Space-faults are characterized by the qubit affected and the time of occurrence.

**Time-fault (measurement error)**: An error where the result of a quantum measurement is reported incorrectly. The actual measurement projects onto an eigenspace, but the classical outcome is flipped. Time-faults are characterized by the measurement affected and the time step.

**State initialization fault**: Treated as equivalent to a time-fault. A faulty initialization of state $|\psi\rangle$ is modeled as perfect initialization followed by an immediate space-fault.

**Spacetime fault**: A collection of space-faults and time-faults occurring at various locations and times during the procedure. The set of all spacetime faults forms a group under composition.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_8: Detector}
\label{Def_8}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 18/47

\noindent\textbf{Dependencies:} \hyperref[Def_7]{Def_7}

\begin{definition*}[Detector]
A **detector** is a collection of state initializations and measurements that yield a deterministic result in the absence of faults. Specifically, a detector is a subset $D$ of initialization events and measurement events such that:

1. In a fault-free execution, the product of all measurement outcomes in $D$ (treating $+1$ outcomes as $0$ and $-1$ outcomes as $1$ modulo 2) combined with initialization parities equals a fixed value (conventionally $+1$ or equivalently $0 \mod 2$).

2. This determinism holds regardless of the quantum state being processed (for measurements of stabilizer generators) or is guaranteed by the initialization (for measurements immediately following initialization).

Intuitively, a detector is a parity check on measurement outcomes that should always yield $+1$ if no errors occurred. A fault that causes a detector to report $-1$ instead is said to **violate** that detector.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_9: Syndrome}
\label{Def_9}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 19/47

\noindent\textbf{Dependencies:} \hyperref[Def_7]{Def_7}, \hyperref[Def_8]{Def_8}

\begin{definition*}[Syndrome]
The **syndrome** of a spacetime fault $F$ is the set of detectors violated by $F$. Formally:
$$\text{syndrome}(F) = \{D : D \text{ is a detector and } D \text{ reports } -1 \text{ in the presence of } F\}$$

Equivalently, the syndrome is the binary vector over the set of all detectors, where entry $D$ is 1 if detector $D$ is violated and 0 otherwise.

Key properties:
1. The syndrome function is $\mathbb{Z}_2$-linear: $\text{syndrome}(F_1 \cdot F_2) = \text{syndrome}(F_1) + \text{syndrome}(F_2)$ (symmetric difference).
2. A spacetime stabilizer (trivial fault) has empty syndrome.
3. A **logical fault** is a non-trivial fault with empty syndrome.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_10: SpacetimeLogicalFault}
\label{Def_10}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 20/47

\noindent\textbf{Dependencies:} \hyperref[Def_9]{Def_9}

\begin{definition*}[SpacetimeLogicalFault]
A **spacetime logical fault** is a collection of space-faults and time-faults that:
1. Does not violate any detector (has empty syndrome), AND
2. Causes a logical error, i.e., changes the outcome of the gauging measurement or introduces a logical Pauli error on the encoded quantum information.

A **spacetime stabilizer** is a collection of space-faults and time-faults that:
1. Does not violate any detector (has empty syndrome), AND
2. Does NOT affect the logical information or measurement outcome.

Every fault with empty syndrome is either a spacetime stabilizer (trivial) or a spacetime logical fault (non-trivial). The set of spacetime stabilizers forms a group, and two faults are **equivalent** if they differ by a spacetime stabilizer.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_11: SpacetimeFaultDistance}
\label{Def_11}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 21/47

\noindent\textbf{Dependencies:} \hyperref[Def_10]{Def_10}

\begin{definition*}[SpacetimeFaultDistance]
The **spacetime fault-distance** of the fault-tolerant gauging measurement procedure is defined as:
$$d_{\text{spacetime}} = \min\{|F| : F \text{ is a spacetime logical fault}\}$$
where $|F|$ denotes the weight of $F$, counted as the total number of:
- Single-qubit Pauli errors (each $X$, $Y$, or $Z$ error on one qubit at one time counts as weight 1), plus
- Single measurement errors (each incorrectly reported measurement counts as weight 1), plus  
- Single initialization errors (each faulty initialization counts as weight 1).

Intuitively, $d_{\text{spacetime}}$ is the minimum number of independent faults required to cause a logical error without being detected.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_12: TimeStepConvention}
\label{Def_12}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 22/47

\begin{definition*}[TimeStepConvention]
We use a half-integer time step convention for the fault-tolerant gauging measurement procedure:

**Integer time steps** $t = 0, 1, 2, \ldots$: Associated with qubit states and Pauli space-errors. A Pauli error 'at time $t$' affects the state between measurement rounds at times $t - \frac{1}{2}$ and $t + \frac{1}{2}$.

**Half-integer time steps** $t + \frac{1}{2}$: Associated with measurements and measurement errors. A measurement 'at time $t + \frac{1}{2}$' occurs between qubit states at times $t$ and $t + 1$.

**Key time points**:
- $t_0$: Start of the procedure
- $t_i$: Time of the initial gauging code deformation (edge qubit initialization and first $A_v$ measurements at $t_i - \frac{1}{2}$ and $t_i + \frac{1}{2}$)
- $t_o$: Time of the final ungauging code deformation (last $A_v$ measurements and edge qubit readout at $t_o - \frac{1}{2}$ and $t_o + \frac{1}{2}$)
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Lem_1: DeformedCode}
\label{Lem_1}

\noindent\textbf{Type:} Lemma \hfill \textbf{Formalization Order:} 23/47

\noindent\textbf{Dependencies:} \hyperref[Def_2]{Def_2}, \hyperref[Def_3]{Def_3}, \hyperref[Def_5]{Def_5}, \hyperref[Def_1]{Def_1}

\begin{lemma*}[DeformedCode]
The following operators form a generating set of stabilizer checks for the deformed (gauged) code:

1. **Gauss's law operators**: $A_v = X_v \prod_{e \ni v} X_e$ for all $v \in V_G$.

2. **Flux operators**: $B_p = \prod_{e \in p} Z_e$ for a generating set of cycles $\{p\}$ of $G$.

3. **Deformed checks**: $\tilde{s}_j = s_j \prod_{e \in \gamma_j} Z_e$ for all checks $s_j$ in the original code, where $\gamma_j$ is an edge-path satisfying $\partial \gamma_j = \mathcal{S}_{Z,j} \cap V_G$ (the Z-type support of $s_j$ restricted to the gauged vertices).

Moreover, the logical subspace of the deformed code has dimension $2^{k-1}$, one qubit less than the original $2^k$-dimensional logical subspace, corresponding to the measured logical $L$.
\end{lemma*}

\begin{proof}
We verify each type of operator becomes a stabilizer and that the dimension count is correct.

**Part 1: $A_v$ operators become stabilizers.**

The $A_v$ operators are explicitly measured during the gauging procedure. By the measurement postulate of quantum mechanics, after measuring $A_v$ with outcome $\varepsilon_v \in \{+1, -1\}$, the state is projected into the $\varepsilon_v$-eigenspace of $A_v$. By tracking outcomes (or applying conditional Pauli corrections $X_v$ when $\varepsilon_v = -1$), we can ensure the code is in the $+1$ eigenspace of all $A_v$. Therefore, each $A_v$ is a stabilizer of the deformed code.

**Part 2: $B_p$ operators are stabilizers.**

We show $B_p$ stabilizes the state in two steps:

**Step 2a: Initial eigenvalue is $+1$.** Initially, edge qubits are in state $|0\rangle^{\otimes E_G}$. For any edge $e$, we have $Z_e|0\rangle_e = (+1)|0\rangle_e$ because $|0\rangle$ is the $+1$ eigenstate of $Z$. Therefore, for any cycle $p$, we compute:
$$B_p|0\rangle^{\otimes E_G} = \left(\prod_{e \in p} Z_e\right)|0\rangle^{\otimes E_G} = \left(\prod_{e \in p} (+1)\right)|0\rangle^{\otimes E_G} = (+1)|0\rangle^{\otimes E_G}$$

**Step 2b: $B_p$ commutes with all $A_v$.** To verify $[B_p, A_v] = 0$, we count anticommuting pairs of operators. The only potential anticommutations arise between $Z_e$ factors of $B_p$ and $X_e$ factors of $A_v$. The operator $A_v = X_v \prod_{e \ni v} X_e$ contains $X_e$ for each edge $e$ incident to $v$.

Now, how many edges of cycle $p$ are incident to vertex $v$? Consider two cases:
- If $v \notin p$ (vertex not on the cycle): No edges of $p$ are incident to $v$, so 0 anticommutations.
- If $v \in p$ (vertex on the cycle): Exactly 2 edges of $p$ are incident to $v$ (the two edges entering and leaving $v$ along the cycle), so 2 anticommutations.

In both cases, the number of anticommutations is even. Since each anticommutation contributes a factor of $(-1)$, the total sign is $(-1)^{\text{even}} = +1$, meaning $B_p A_v = A_v B_p$.

Since $B_p$ has initial eigenvalue $+1$ and commutes with all measured operators $A_v$, it remains a stabilizer of the deformed code.

**Part 3: $\tilde{s}_j$ operators are stabilizers.**

We show that $\tilde{s}_j = s_j \prod_{e \in \gamma_j} Z_e$ commutes with all $A_v$ operators.

**Step 3a: Counting anticommutations.** For a fixed vertex $v$, we count how many anticommuting pairs arise between $\tilde{s}_j$ and $A_v$:

- From $s_j$: The operator $s_j$ contains a $Z_v$ factor if and only if $v \in \mathcal{S}_{Z,j}$ (the Z-type support of $s_j$). If $v \in \mathcal{S}_{Z,j} \cap V_G$, then $Z_v$ anticommutes with $X_v$ in $A_v$, contributing 1 anticommutation.

- From $\prod_{e \in \gamma_j} Z_e$: Each $Z_e$ with $v \in e$ (edge incident to $v$) anticommutes with $X_e$ in $A_v$. The number of such edges equals $(\partial \gamma_j)_v$ (the $v$-component of the boundary of $\gamma_j$, which counts edges in $\gamma_j$ incident to $v$ modulo 2).

**Step 3b: Boundary condition ensures cancellation.** By definition of $\gamma_j$, we have $\partial \gamma_j = \mathcal{S}_{Z,j} \cap V_G$. Therefore:
- $(\partial \gamma_j)_v = 1$ if and only if $v \in \mathcal{S}_{Z,j} \cap V_G$.

This means the number of anticommutations from $s_j$ (which is 1 if $v \in \mathcal{S}_{Z,j} \cap V_G$, else 0) exactly equals the number from $\prod_{e \in \gamma_j} Z_e$ (which is $(\partial \gamma_j)_v$). The total number of anticommutations is therefore:
$$1_{v \in \mathcal{S}_{Z,j} \cap V_G} + (\partial \gamma_j)_v = 2 \cdot 1_{v \in \mathcal{S}_{Z,j} \cap V_G} \equiv 0 \pmod{2}$$

Since the total is even, we have $[\tilde{s}_j, A_v] = 0$ for all $v$.

**Step 3c: Initial eigenvalue.** The original stabilizer $s_j$ has eigenvalue $+1$ on the code state. The edge operators $Z_e$ each have eigenvalue $+1$ on the initial $|0\rangle_e$ state. Therefore:
$$\tilde{s}_j |\psi\rangle|0\rangle^{\otimes E_G} = s_j|\psi\rangle \cdot \prod_{e \in \gamma_j}(+1)|0\rangle^{\otimes E_G} = (+1)|\psi\rangle|0\rangle^{\otimes E_G}$$

So $\tilde{s}_j$ has initial eigenvalue $+1$ and remains a stabilizer.

**Part 4: Dimension count.**

Original system: $n$ qubits, $(n - k)$ independent stabilizers, code space dimension $2^k$.

Deformed system:
- Qubits: $n + |E_G|$ (original qubits plus edge qubits).
- New X-type stabilizers from $A_v$: There are $|V_G|$ operators $A_v$, but they satisfy one relation: $\prod_{v \in V_G} A_v = L \cdot \prod_e X_e^2 = L$ (since $X_e^2 = I$). So $(|V_G| - 1)$ are independent, plus the logical $L$ is now a stabilizer.
- New Z-type stabilizers from $B_p$: There are $C = |E_G| - |V_G| + 1$ independent cycles (by Euler's formula for connected graphs), giving $C$ independent $B_p$ operators.
- Original stabilizers become $\tilde{s}_j$: $(n - k)$ operators.

Total independent stabilizers:
$$(|V_G| - 1 + 1) + (|E_G| - |V_G| + 1) + (n - k) = |E_G| + (n - k) + 1$$

The $+1$ accounts for the logical $L$ becoming a stabilizer. Code space dimension:
$$2^{(n + |E_G|) - (|E_G| + n - k + 1)} = 2^{k-1}$$

This confirms exactly one logical qubit (corresponding to $L$) has been measured.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Lem_2: SpaceDistance}
\label{Lem_2}

\noindent\textbf{Type:} Lemma \hfill \textbf{Formalization Order:} 24/47

\noindent\textbf{Dependencies:} \hyperref[Def_6]{Def_6}, \hyperref[Rem_5]{Rem_5}, \hyperref[Def_1]{Def_1}, \hyperref[Def_4]{Def_4}, \hyperref[Rem_7]{Rem_7}

\begin{lemma*}[SpaceDistance]
The distance $d^*$ of the deformed code satisfies:
$$d^* \geq \min(h(G), 1) \cdot d$$
where $h(G)$ is the Cheeger constant of $G$ and $d$ is the distance of the original code. In particular, if $h(G) \geq 1$, then $d^* \geq d$.
\end{lemma*}

\begin{proof}
We prove that any logical operator $L'$ in the deformed code has weight at least $\min(h(G), 1) \cdot d$.

**Step 1: Structure of a deformed logical operator.**

Any logical operator on the deformed code can be written as:
$$L' = (i)^{\sigma} L_X^V L_Z^V L_X^E L_Z^E \tilde{L}$$
where:
- $\tilde{L}$ is the support on qubits that don't intersect the gauged region
- $L_X^V = \prod_{v \in \mathcal{S}_X \cap V_{G_0}} X_v$ captures X-support on original vertices
- $L_X^E = \prod_{e \in \mathcal{S}_X \cap E_{\bar{\bar{G}}}} X_e$ captures X-support on edge qubits
- $L_Z^V, L_Z^E$ are analogous for Z-support

**Step 2: X-type component must be a cocycle.**

The logical operator $L'$ must commute with all $B_p$ flux operators. Consider the commutator $[L', B_p]$. Since $B_p = \prod_{e \in p} Z_e$ consists only of $Z_e$ operators, the only part of $L'$ that can anticommute is the $X_e$ part, namely $L_X^E$.

For each edge $e \in p$, if $e \in \mathcal{S}_X^E$ (meaning $L_X^E$ contains $X_e$), then $X_e$ anticommutes with $Z_e$. So:
$$[L_X^E, B_p] = (-1)^{|p \cap \mathcal{S}_X^E|} \text{ (meaning they anticommute if the intersection has odd size)}$$

For $L'$ to commute with all $B_p$, we need $|p \cap \mathcal{S}_X^E| \equiv 0 \pmod{2}$ for all cycles $p$. This exactly means $\mathcal{S}_X^E$ is a 1-cocycle: $\delta_2 \mathcal{S}_X^E = 0$.

**Step 3: Cocycle is a coboundary.**

Since the $B_p$ operators are defined on a generating set of cycles, the sequence formed by $\delta, \delta_2$ is exact (see Rem_7). This means $\ker(\delta_2) = \text{im}(\delta)$. Since $\mathcal{S}_X^E \in \ker(\delta_2)$, there exists a vertex set $\tilde{\mathcal{S}}_X^V \subseteq V_{\bar{\bar{G}}}$ such that:
$$\mathcal{S}_X^E = \delta \tilde{\mathcal{S}}_X^V$$

In other words, the edges in $\mathcal{S}_X^E$ are exactly those crossing the cut defined by $\tilde{\mathcal{S}}_X^V$ (edges with exactly one endpoint in $\tilde{\mathcal{S}}_X^V$).

**Step 4: Clean using $A_v$ stabilizers.**

Define $\overline{L}_X^V = \prod_{v \in \tilde{\mathcal{S}}_X^V \cap G_0} X_v$. We claim that:
$$L_X^E = \overline{L}_X^V \prod_{v \in \tilde{\mathcal{S}}_X^V} A_v$$

To verify: $\prod_{v \in \tilde{\mathcal{S}}_X^V} A_v = \prod_{v \in \tilde{\mathcal{S}}_X^V} X_v \cdot \prod_{e \in \delta \tilde{\mathcal{S}}_X^V} X_e$. Here:
- $\prod_{v \in \tilde{\mathcal{S}}_X^V} X_v$ includes $X_v$ for vertices in layer 0 (giving $\overline{L}_X^V$) and vertices in other layers (dummy vertices, where $X_v$ acts trivially).
- $\prod_{e \in \delta \tilde{\mathcal{S}}_X^V} X_e = L_X^E$ since $\delta \tilde{\mathcal{S}}_X^V = \mathcal{S}_X^E$.

Therefore, $L'$ is equivalent to:
$$\overline{L} = L' \prod_{v \in \tilde{\mathcal{S}}_X^V} A_v = (i)^{\sigma} L_X^V \overline{L}_X^V L_Z^V L_Z^E \tilde{L}$$

This $\overline{L}$ has no X-support on edge qubits.

**Step 5: Restriction to original qubits.**

The deformed checks $\tilde{s}_j$ differ from original checks $s_j$ only by $Z_e$ operators on edges. The Z-part $L_Z^E$ on edge qubits commutes with all $Z_e$ operators in $\tilde{s}_j$. Therefore, the restriction of $\overline{L}$ to original qubits:
$$\overline{L}|_V = (i)^{\sigma} L_X^V \overline{L}_X^V L_Z^V \tilde{L}$$
must commute with all original checks $s_j$. Since it's a non-identity operator (as $L'$ was a non-trivial logical), $\overline{L}|_V$ is a logical operator of the original code.

**Step 6: Original distance bound.**

Any nontrivial logical operator of the original code has weight at least $d$. Therefore:
$$|\overline{L}|_V| \geq d$$

Since $\overline{L}$ includes $\overline{L}|_V$ plus possibly some $L_Z^E$ on edges, we have $|\overline{L}| \geq |\overline{L}|_V| \geq d$.

**Step 7: Cheeger constant bound on cleaning.**

We now bound the weight change when going from $\overline{L}$ back to $L'$.

We can ensure $|\tilde{\mathcal{S}}_X^V \cap G_0| \leq \frac{|V_G|}{2}$ by optionally multiplying by $\prod_{v \in V_{\bar{\bar{G}}}} A_v$ (which equals $L$, since $\prod_v A_v = L$). If this product gives fewer vertices, we use it.

**Step 7a: Single layer case.** For a single layer (no cycle-sparsification), when converting from $\overline{L}$ to $L' = \overline{L} \cdot \prod_{v \in \tilde{\mathcal{S}}_X^V} A_v$:
- We lose X-support on vertices in $\tilde{\mathcal{S}}_X^V$: weight reduction of $|\tilde{\mathcal{S}}_X^V|$.
- We gain X-support on edges in $\delta \tilde{\mathcal{S}}_X^V$: weight gain of $|\delta \tilde{\mathcal{S}}_X^V|$.

By the Cheeger constant definition: $|\delta \tilde{\mathcal{S}}_X^V| \geq h(G) |\tilde{\mathcal{S}}_X^V|$ when $|\tilde{\mathcal{S}}_X^V| \leq |V_G|/2$.

So $|L'| \geq |\overline{L}| - |\tilde{\mathcal{S}}_X^V| + |\delta \tilde{\mathcal{S}}_X^V| \geq |\overline{L}| + (h(G) - 1)|\tilde{\mathcal{S}}_X^V|$.

If $h(G) \geq 1$, then $|L'| \geq |\overline{L}| \geq d$.

**Step 7b: Multi-layer case.** For the cycle-sparsified graph $\bar{\bar{G}}$, partition $\tilde{\mathcal{S}}_X^V \cap G_0$ into:
- **Type 1**: Vertices $v$ where not all copies across layers are in $\tilde{\mathcal{S}}_X^V$.
- **Type 2**: Vertices $v$ where all copies are in $\tilde{\mathcal{S}}_X^V$.

For Type 1 vertices: At least one inter-layer edge survives in $L'$ (connecting a cleaned copy to an uncleaned copy).

For Type 2 vertices: The boundary edges in each layer give X-support. The projection onto layer 0 gives edges in $\partial(\text{Type 2})$, and by Cheeger: $|\partial(\text{Type 2})| \geq h(G) \cdot |\text{Type 2}|$.

Combining these observations, we still get $|L'| \geq \min(h(G), 1) \cdot |\overline{L}|_V| \geq \min(h(G), 1) \cdot d$.

**Step 8: Final weight bound.**

For $h(G) \geq 1$: $|L'| \geq d$.

For $h(G) < 1$: $|L'| \geq h(G) \cdot d$.

Combining: $d^* \geq \min(h(G), 1) \cdot d$.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Lem_3: SpacetimeCodeDetectors}
\label{Lem_3}

\noindent\textbf{Type:} Lemma \hfill \textbf{Formalization Order:} 25/47

\noindent\textbf{Dependencies:} \hyperref[Def_8]{Def_8}, \hyperref[Def_12]{Def_12}, \hyperref[Lem_1]{Lem_1}, \hyperref[Def_5]{Def_5}, \hyperref[Def_3]{Def_3}

\begin{lemma*}[SpacetimeCodeDetectors]
The following form a generating set of local detectors in the fault-tolerant gauging measurement procedure:

**For $t < t_i$ and $t > t_o$:**
- $s_j^t$: the repeated measurement detector given by comparing the $s_j$ check measurements at times $t - \frac{1}{2}$ and $t + \frac{1}{2}$.

**For $t_i < t < t_o$:**
- $A_v^t$: repeated measurement of the Gauss's law check $A_v$ at times $t - \frac{1}{2}$ and $t + \frac{1}{2}$.
- $B_p^t$: repeated measurement of the flux check $B_p$ at times $t - \frac{1}{2}$ and $t + \frac{1}{2}$.
- $\tilde{s}_j^t$: repeated measurement of the deformed check $\tilde{s}_j$ at times $t - \frac{1}{2}$ and $t + \frac{1}{2}$.

**For $t = t_i$:**
- $B_p^{t_i}$: the measurement of $B_p$ at time $t_i + \frac{1}{2}$ combined with the initialization of edge qubits $e \in p$ in state $|0\rangle_e$ at time $t_i - \frac{1}{2}$. (Since $B_p|0\rangle^{\otimes p} = |0\rangle^{\otimes p}$, this detector is satisfied when no faults occur.)
- $\tilde{s}_j^{t_i}$: the measurement of $s_j$ at $t_i - \frac{1}{2}$, initialization of edges $e \in \gamma_j$ in $|0\rangle$, and measurement of $\tilde{s}_j$ at $t_i + \frac{1}{2}$.

**For $t = t_o$:**
- $B_p^{t_o}$: the measurement of $B_p$ at $t_o - \frac{1}{2}$ combined with $Z_e$ measurements on edges $e \in p$ at $t_o + \frac{1}{2}$.
- $\tilde{s}_j^{t_o}$: the measurement of $\tilde{s}_j$ at $t_o - \frac{1}{2}$, $Z_e$ measurements on edges $e \in \gamma_j$, and measurement of $s_j$ at $t_o + \frac{1}{2}$.
\end{lemma*}

\begin{proof}
We verify that each listed collection forms a valid detector (deterministic outcome in the absence of faults) and that these generate all local detectors.

**Part 1: Verification that each is a valid detector.**

**Repeated measurement detectors ($t \neq t_i, t_o$):**

For any stabilizer check $c$ (whether $s_j$, $\tilde{s}_j$, $A_v$, or $B_p$), measuring $c$ twice on a state in the code space yields the same outcome both times. This is because:

1. The state is in the $+1$ eigenspace of $c$ (since $c$ is a stabilizer).
2. The first measurement yields $+1$ and leaves the state unchanged.
3. The second measurement also yields $+1$.

The detector "product of outcomes = $+1$" is satisfied: $(+1) \times (+1) = +1$.

**$B_p^{t_i}$ detector:**

Edge qubits start in $|0\rangle_e$. For each edge $e$, $Z_e|0\rangle_e = (+1)|0\rangle_e$. Therefore:
$$B_p|0\rangle^{\otimes p} = \prod_{e \in p} Z_e |0\rangle^{\otimes p} = \prod_{e \in p} (+1) |0\rangle^{\otimes p} = (+1)|0\rangle^{\otimes p}$$

So the measurement of $B_p$ at time $t_i + \frac{1}{2}$ yields $+1$.

The detector is: (product of init parities) $\times$ (measurement outcome) = $+1$.
- Init parity of each $|0\rangle$ is $+1$ (by convention, initializing $|0\rangle$ contributes parity $+1$).
- Product: $\prod_e (+1) \times (+1) = +1$. ✓

**$\tilde{s}_j^{t_i}$ detector:**

Recall $\tilde{s}_j = s_j \prod_{e \in \gamma_j} Z_e$.

1. Measurement of $s_j$ at $t_i - \frac{1}{2}$: The state is in the original code space, so $s_j$ yields $+1$.
2. Edge initialization: Each $e \in \gamma_j$ is initialized to $|0\rangle$.
3. Measurement of $\tilde{s}_j$ at $t_i + \frac{1}{2}$: The state is $(\text{code state}) \otimes |0\rangle^{\otimes \gamma_j}$.

Compute the eigenvalue of $\tilde{s}_j$:
$$\tilde{s}_j = s_j \prod_{e \in \gamma_j} Z_e$$
- $s_j$ has eigenvalue $+1$ on the code state.
- Each $Z_e$ has eigenvalue $+1$ on $|0\rangle_e$.
- Product: $(+1) \times \prod_{e \in \gamma_j}(+1) = +1$.

Detector: $s_j \text{ outcome} \times \tilde{s}_j \text{ outcome} = (+1) \times (+1) = +1$. ✓

**$B_p^{t_o}$ and $\tilde{s}_j^{t_o}$ detectors:**

Similar analysis. At $t_o - \frac{1}{2}$, we measure stabilizers of the deformed code (eigenvalue $+1$). At $t_o + \frac{1}{2}$, we measure $Z_e$ on edges (reading out their computational basis state) and original stabilizers $s_j$.

For $B_p^{t_o}$: The product $\prod_{e \in p} Z_e$ (from individual $Z_e$ measurements) equals the outcome of $B_p$ from time $t_o - \frac{1}{2}$. Both are $+1$ in the absence of faults.

For $\tilde{s}_j^{t_o}$: The measurement of $\tilde{s}_j$ at $t_o - \frac{1}{2}$ yields $+1$. The product of $s_j$ outcome and $\prod_{e \in \gamma_j} z_e$ (where $z_e$ is the $Z_e$ measurement outcome) reconstructs the $\tilde{s}_j$ value, which is $+1$.

**Part 2: Completeness - these generate all local detectors.**

**Away from boundaries:** In repeated measurement, any detector must compare measurements of the same check at different times. The minimal such detector compares adjacent time steps. Detectors comparing non-adjacent times $(t, t+k)$ factor as:
$$(t, t+1) \times (t+1, t+2) \times \cdots \times (t+k-1, t+k)$$

**At boundaries:** Detectors involving initialization must include a product of $Z$-type operators (since $|0\rangle$ is a $Z$ eigenstate). Any such product that yields a deterministic outcome must be a product of stabilizers. The only stabilizers involving edge qubits at initialization are the $B_p$ and $\tilde{s}_j$ checks. These are captured by the listed boundary detectors.

Crossing-boundary detectors (involving both $s_j$ and $\tilde{s}_j$) decompose into repeated measurement detectors plus boundary detectors.

**Local relations assumption:** We assume no space-only local relations (meta-checks) in the original code. If present, those would add additional detectors at each time step.

Therefore, the listed detectors generate all local detectors.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Lem_4: SpacetimeStabilizers}
\label{Lem_4}

\noindent\textbf{Type:} Lemma \hfill \textbf{Formalization Order:} 26/47

\noindent\textbf{Dependencies:} \hyperref[Def_7]{Def_7}, \hyperref[Def_8]{Def_8}, \hyperref[Def_9]{Def_9}, \hyperref[Lem_1]{Lem_1}

\begin{lemma*}[SpacetimeStabilizers]
The following form a generating set of local spacetime stabilizers for the fault-tolerant gauging measurement procedure:

**For $t < t_i$ and $t > t_o$ (in the original code):**
1. A stabilizer check operator $s_j$ at time $t$.
2. A pair of Pauli $X_q$ (or $Z_q$) faults at times $t, t+1$, together with measurement faults on all checks $s_j$ that anticommute with $X_q$ (or $Z_q$) at time $t + \frac{1}{2}$.

**For $t_i < t < t_o$ (in the deformed code):**
1. A stabilizer check operator $\tilde{s}_j$, $A_v$, or $B_p$ at time $t$.
2. A pair of vertex Pauli $X_v$ faults at times $t, t+1$, with measurement faults on all checks $\tilde{s}_j$ anticommuting with $X_v$ at time $t + \frac{1}{2}$.
3. A pair of vertex Pauli $Z_v$ faults at times $t, t+1$, with measurement faults on $A_v$ and all checks $\tilde{s}_j$ anticommuting with $Z_v$ at time $t + \frac{1}{2}$.
4. A pair of edge Pauli $X_e$ faults at times $t, t+1$, with measurement faults on checks $B_p$ with $p \ni e$ and all checks $\tilde{s}_j$ anticommuting with $X_e$ at time $t + \frac{1}{2}$.
5. A pair of edge Pauli $Z_e$ faults at times $t, t+1$, with measurement faults on checks $A_v$ with $v \in e$ at time $t + \frac{1}{2}$.

**For $t = t_i$ (initial gauging boundary):**
1. A stabilizer check operator $s_j$ or $Z_e$ at time $t$.
2. Vertex Pauli pairs as in the deformed code case.
3. Edge $X_e$ pairs as in the deformed code case.
4. A $|0\rangle_e$ initialization fault at time $t - \frac{1}{2}$ together with a Pauli $X_e$ fault at time $t$.
5. A Pauli $Z_e$ edge fault at time $t+1$ together with a pair of $A_v$ measurement faults for $v \in e$ at time $t + \frac{1}{2}$.

**For $t = t_o$ (final ungauging boundary):**
1. A stabilizer check operator $\tilde{s}_j$, $A_v$, or $B_p$ at time $t$.
2. Vertex Pauli pairs transitioning to original code checks.
3. A Pauli $X_e$ edge fault at time $t$ together with a measurement fault on check $Z_e$ at time $t + \frac{1}{2}$.
4. A Pauli $Z_e$ edge fault at time $t$.
5. A Pauli $Z_e$ edge fault at time $t-1$ together with a pair of $A_v$ measurement faults for $v \in e$ at time $t - \frac{1}{2}$.
\end{lemma*}

\begin{proof}
We verify that each listed fault pattern has empty syndrome and doesn't affect logical information.

**General principle:** A spacetime stabilizer must:
(a) Have empty syndrome (violate no detectors)
(b) Not change the logical measurement outcome or introduce logical errors

**Verification of Type 1 (space stabilizers):**

A stabilizer check $s_j$ (or $\tilde{s}_j$, $A_v$, $B_p$) applied at time $t$ as a "fault" acts on the state by multiplying by the stabilizer. Since the state is in the code space (the $+1$ eigenspace of all stabilizers), this does nothing: $s_j|\psi\rangle = |\psi\rangle$.

- Syndrome: Zero, because the state hasn't changed, so all measurement outcomes are unaffected.
- Logical effect: None, since $s_j$ acts as identity on the code space.

**Verification of Type 2 (Pauli pairs with measurement errors):**

Consider a Pauli fault $P$ at times $t$ and $t+1$, with measurement faults on all checks $c$ that anticommute with $P$ at time $t + \frac{1}{2}$.

**Syndrome analysis:** We analyze which detectors are violated.

*Detector $c^t$ (comparing measurements at $t-\frac{1}{2}$ and $t+\frac{1}{2}$):*
- Measurement at $t - \frac{1}{2}$: Occurs before the Pauli fault at time $t$, so unaffected.
- Measurement at $t + \frac{1}{2}$: Affected if $[P, c] \neq 0$.
  - Physical effect: $P$ at time $t$ flips the outcome (since $Pc = -cP$ for anticommuting operators).
  - Measurement fault: Also flips the recorded outcome.
  - Net effect on recorded outcome: Flipped twice = original outcome.
- Result: Detector $c^t$ is NOT violated.

*Detector $c^{t+1}$ (comparing measurements at $t+\frac{1}{2}$ and $t+\frac{3}{2}$):*
- Measurement at $t + \frac{1}{2}$: Flipped by measurement fault (if $[P,c] \neq 0$).
- Measurement at $t + \frac{3}{2}$: After $P$ at time $t+1$. The state has $P$ applied at $t$ and $P$ applied at $t+1$, so net effect $P \cdot P = I$. The outcome at $t+\frac{3}{2}$ is unaffected.
  - Wait, but there's also the measurement fault effect...
  - Actually, the $P$ at $t+1$ acts AFTER the measurement at $t+\frac{1}{2}$ but BEFORE the measurement at $t+\frac{3}{2}$.
  - So measurement at $t+\frac{3}{2}$: Affected by $P$ at $t+1$ if $[P,c] \neq 0$ → flipped.
  - Measurement fault at $t+\frac{1}{2}$: Flips recorded outcome at $t+\frac{1}{2}$.
- Result: 
  - Recorded outcome at $t+\frac{1}{2}$: Flipped by $P$ at $t$ AND flipped by measurement fault = original.
  - Actual outcome at $t+\frac{3}{2}$: Flipped by $P$ at $t+1$.
  - Detector $c^{t+1}$ compares (original) with (flipped) = different → VIOLATED?
  
Let me reconsider more carefully:

*Corrected analysis:*
- $P$ at time $t$: Affects measurements at times $> t$, specifically at $t+\frac{1}{2}$.
- $P$ at time $t+1$: Affects measurements at times $> t+1$, specifically at $t+\frac{3}{2}$.

For anticommuting check $c$:
- Outcome at $t+\frac{1}{2}$: Flipped by $P$ at $t$. Recorded as flipped due to measurement fault. Net recorded: unflipped.
- Outcome at $t+\frac{3}{2}$: Flipped by $P$ at $t$ (still active) AND flipped by $P$ at $t+1$. Net: unflipped.

Wait, Pauli errors compose: $P \cdot P = I$. So after both errors:
- State at time $t+\frac{3}{2}$: Has had $P$ applied twice, so back to original state.
- Outcome at $t+\frac{3}{2}$: Same as without errors.

- Recorded outcome at $t+\frac{1}{2}$: Physical flip (from $P$ at $t$) + measurement fault flip = no net flip.
- Actual outcome at $t+\frac{3}{2}$: No flip (since $P^2 = I$).

*Detector $c^{t+1}$: Compares (no flip) with (no flip) = NOT violated.* ✓

*For commuting checks:* Not affected by $P$ or measurement faults (no measurement faults on them).

So the syndrome is empty.

**Logical effect:** $P \cdot P = I$, so the two Pauli errors cancel. The measurement errors don't affect the quantum state. The recorded syndrome is empty, and no logical error is introduced.

**Verification of boundary stabilizers:**

*At $t = t_i$, the stabilizer "$|0\rangle_e$ init fault + $X_e$ at $t$":*
- A $|0\rangle_e$ initialization fault is equivalent to preparing $|1\rangle_e = X_e|0\rangle_e$ instead of $|0\rangle_e$.
- Following the fault with $X_e$ at time $t = t_i$ gives: $X_e |1\rangle_e = |0\rangle_e$.
- Net effect: State is $|0\rangle_e$ as intended.
- Syndrome: Empty (detectors involving this edge see no difference).
- Logical effect: None.

*At $t = t_o$, the stabilizer "$X_e$ at $t$ + $Z_e$ measurement fault at $t+\frac{1}{2}$":*
- $X_e$ at time $t_o$ flips the state from $|z\rangle_e$ to $|1-z\rangle_e$.
- $Z_e$ measurement at $t_o + \frac{1}{2}$: Would measure $1-z$, but measurement fault flips record to $z$.
- Net recorded outcome: Same as without error ($z$).
- Syndrome: Empty.
- Logical effect: None (the edge qubit is being discarded).

**Completeness argument:**

Any local spacetime stabilizer must involve either:
1. Only space operators: Then it's a product of space stabilizers at some time.
2. Space operators at multiple times with measurement errors for syndrome cancellation.

The second case: The product of Pauli operators across all times must itself be a space stabilizer. This product can be built from pairs of identical Paulis at adjacent times using the listed generators.

Therefore, the listed generators span all local spacetime stabilizers.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Lem_5: TimeFaultDistance}
\label{Lem_5}

\noindent\textbf{Type:} Lemma \hfill \textbf{Formalization Order:} 27/47

\noindent\textbf{Dependencies:} \hyperref[Def_7]{Def_7}, \hyperref[Def_8]{Def_8}, \hyperref[Def_10]{Def_10}, \hyperref[Def_12]{Def_12}, \hyperref[Lem_1]{Lem_1}, \hyperref[Lem_4]{Lem_4}

\begin{lemma*}[TimeFaultDistance]
The fault-distance for pure measurement and initialization errors (time-faults) is exactly $(t_o - t_i)$, where $t_i$ is the time of the initial gauging deformation and $t_o$ is the time of the final ungauging deformation.
\end{lemma*}

\begin{proof}
We prove both the lower bound and the matching upper bound.

**Part 1: Lower bound argument.**

Assume perfect initial and final measurement rounds (as per our convention in Def_12). Under this assumption, any pure measurement/initialization logical fault must start and end at the code deformation boundaries $t_i$ and $t_o$.

**Why faults can't extend beyond $t_i$ and $t_o$:** 

A measurement fault at time $t + \frac{1}{2}$ on check $c$ violates exactly two detectors: $c^t$ (comparing $t-\frac{1}{2}$ and $t+\frac{1}{2}$) and $c^{t+1}$ (comparing $t+\frac{1}{2}$ and $t+\frac{3}{2}$).

For the syndrome to be empty, these violations must be cancelled. This requires:
- Either another fault at time $t - \frac{1}{2}$ or $t + \frac{3}{2}$ on the same check $c$, OR
- The fault terminates at a boundary where detector structure changes.

The only boundaries where detector structure changes are at $t_i$ and $t_o$.

**Part 2: Characterize time-fault strings.**

A string of measurement faults (on the same check at consecutive times) can terminate at $t_i$ in two ways:

**Termination Type 1: $A_v$ string.**
A sequence of $A_v$ measurement faults at times $t_i + \frac{1}{2}, t_i + \frac{3}{2}, \ldots$.
- The first fault at $t_i + \frac{1}{2}$ violates detector $A_v^{t_i+1}$ (if it exists) but not $A_v^{t_i}$ because detector $A_v^{t_i}$ only involves the single measurement at $t_i + \frac{1}{2}$ (the first $A_v$ measurement).
- Actually, at $t = t_i$, there is no $A_v^{t_i}$ detector of the form "repeated measurement" because there's no $A_v$ measurement before $t_i + \frac{1}{2}$.
- So the string can start at $t_i + \frac{1}{2}$ without violating any detector at the start.

**Termination Type 2: Edge initialization fault.**
A $|0\rangle_e$ initialization fault at $t_i - \frac{1}{2}$ violates:
- $B_p^{t_i}$ for all cycles $p \ni e$ (because $B_p$ measurement at $t_i + \frac{1}{2}$ is affected).
- $\tilde{s}_j^{t_i}$ for all checks with $e \in \gamma_j$.

A chain of $B_p$ and $\tilde{s}_j$ measurement faults can terminate here.

Similarly at $t_o$:

**Termination Type 1:** The final $A_v$ measurement at $t_o - \frac{1}{2}$ has no detector comparing it to a later $A_v$ measurement. So $A_v$ strings can end here.

**Termination Type 2:** A $Z_e$ readout fault at $t_o + \frac{1}{2}$ is equivalent to an $X_e$ fault on the state (it reports the wrong bit). This affects detectors $B_p^{t_o}$ and $\tilde{s}_j^{t_o}$, allowing those strings to terminate.

**Part 3: Identify the logical time-faults.**

**Type 1: $A_v$ measurement fault string.**
Faults on all $(t_o - t_i)$ measurements of some $A_v$ check (at times $t_i + \frac{1}{2}, t_i + \frac{3}{2}, \ldots, t_o - \frac{1}{2}$).

- Terminates correctly at both ends (as shown above).
- Syndrome: Empty. Each internal fault at $t + \frac{1}{2}$ violates $A_v^t$ and $A_v^{t+1}$, but adjacent faults cancel these violations pairwise.
- Logical effect: Flipping all $A_v$ outcomes changes $\sigma = \prod_v \varepsilon_v$. Since the logical measurement result is $\sigma$, this changes the inferred logical outcome.

This is a nontrivial logical fault of weight exactly $(t_o - t_i)$.

**Type 2: $B_p$/$\tilde{s}_j$ measurement fault string with edge faults.**
Consider faults:
- $|0\rangle_e$ initialization fault at $t_i - \frac{1}{2}$
- $B_p$ and $\tilde{s}_j$ measurement faults at all intermediate times
- $Z_e$ readout fault at $t_o + \frac{1}{2}$

This has zero syndrome, but is it a logical fault or a spacetime stabilizer?

We show it's a spacetime stabilizer by decomposition:
- Spacetime stabilizer: "init fault + $X_e$ at $t_i$" cancels the init fault and introduces $X_e$ at $t_i$.
- Spacetime stabilizer: "$X_e$ at $t_i$, $X_e$ at $t_i+1$, measurement faults between" moves the $X_e$ forward.
- Continue until $X_e$ at $t_o$.
- Spacetime stabilizer: "$X_e$ at $t_o$ + $Z_e$ readout fault" cancels both.

So this string is a product of spacetime stabilizers = trivial.

**Part 4: Conclusion.**

The minimum weight nontrivial time-fault is the $A_v$ measurement string of weight $(t_o - t_i)$.

- Lower bound: $(t_o - t_i)$ (any time-logical must span from $t_i$ to $t_o$).
- Upper bound: $(t_o - t_i)$ (achieved by the $A_v$ measurement string).

The time fault-distance is exactly $(t_o - t_i)$.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Lem_6: SpacetimeDecoupling}
\label{Lem_6}

\noindent\textbf{Type:} Lemma \hfill \textbf{Formalization Order:} 28/47

\noindent\textbf{Dependencies:} \hyperref[Lem_4]{Lem_4}, \hyperref[Lem_5]{Lem_5}, \hyperref[Def_10]{Def_10}, \hyperref[Def_12]{Def_12}

\begin{lemma*}[SpacetimeDecoupling]
Any spacetime logical fault $F$ is equivalent, up to multiplication by spacetime stabilizers, to the product of a pure space logical fault and a pure time logical fault:
$$F \sim F_{\text{space}} \cdot F_{\text{time}}$$
where $F_{\text{space}}$ consists only of Pauli errors at a single time step, and $F_{\text{time}}$ consists only of measurement/initialization errors.
\end{lemma*}

\begin{proof}
We constructively show how to decouple any spacetime fault into space and time components.

**Step 1: Clean space component to a single time step.**

Consider an arbitrary spacetime logical fault $F$. The space component of $F$ consists of Pauli operators at various time steps.

Using spacetime stabilizers of the form (from Lem_4):
- Pauli $P$ faults at times $t$ and $t+1$, together with measurement faults on all checks that anticommute with $P$ at time $t + \frac{1}{2}$.

We can "move" any Pauli error from time $t$ to time $t \pm 1$ while adding measurement errors.

Specifically, to move $P$ from time $t$ to time $t+1$:
1. Multiply $F$ by the spacetime stabilizer "$P$ at $t$, $P$ at $t+1$, measurement faults between."
2. This adds $P$ at both $t$ and $t+1$, plus measurement faults.
3. Since $P \cdot P = I$, the $P$ at time $t$ cancels the original $P$ at time $t$.
4. Net effect: $P$ has moved from $t$ to $t+1$, with new measurement faults added.

Repeatedly applying this, we can clean all Pauli errors to a single time step, say $t_i$. The resulting fault $F'$ has:
- All Pauli errors at time $t_i$
- Additional measurement errors (from the cleaning process)
- Original measurement errors

**Step 2: Analyze measurement errors in cleaned fault.**

In the cleaned fault $F'$, all measurement errors must lie in the interval $[t_i, t_o]$. This is because:

- Measurement errors outside $[t_i, t_o]$ must form strings that propagate to the initial or final boundary.
- By our perfect boundary convention, the initial and final measurements are perfect.
- A measurement string reaching the boundary would violate a boundary detector.
- But $F'$ is equivalent to the logical fault $F$ (which has empty syndrome), so $F'$ also has empty syndrome.
- Therefore, no measurement strings reach the boundaries.

**Step 3: Characterize measurement error strings.**

Measurement errors in $F'$ form strings through time:
- Each string starts at $t_i \pm \frac{1}{2}$ (at $A_v$ measurement or edge initialization).
- Each string ends at $t_o \pm \frac{1}{2}$ (at $A_v$ measurement or edge readout).

**Strings involving edge readout faults at $t_o + \frac{1}{2}$:**

These correspond to $Z_e$ readout errors, which are equivalent to $X_e$ space errors at time $t_o$.

We "absorb" these into spacetime stabilizers:
1. Add spacetime stabilizer: "$|0\rangle_e$ init fault at $t_i - \frac{1}{2}$" + "$X_e$ fault at $t_i$".
2. This converts the string to one starting from init fault at $t_i$ and ending at readout fault at $t_o$.

After this modification, all such strings are:
- Init fault at $t_i - \frac{1}{2}$
- Measurement faults through the middle
- Readout fault at $t_o + \frac{1}{2}$

By Lem_5, these are exactly the trivial Type 2 time-faults (spacetime stabilizers). They can be removed.

**Step 4: Remaining structure.**

After cleaning, the fault $F'$ has:
- Space component at time $t_i$: some Pauli errors.
- Time component: strings of $A_v$ measurement faults from $t_i$ to $t_o$.

The space component must itself be a logical fault (either trivial or nontrivial) for the combined fault to have empty syndrome.

The time component (if nonempty) consists of $A_v$ measurement strings, which are time-logical faults.

**Step 5: Conclusion.**

We've shown $F \sim F' = F_{\text{space}} \cdot F_{\text{time}}$ where:
- $F_{\text{space}}$ = Pauli errors at time $t_i$ (a space fault)
- $F_{\text{time}}$ = $A_v$ measurement strings (a time fault)

Both components must be logical faults (trivial or nontrivial) for the product to be a logical fault. This completes the decoupling.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Lem_7: SpacetimeFaultDistanceLemma}
\label{Lem_7}

\noindent\textbf{Type:} Lemma \hfill \textbf{Formalization Order:} 29/47

\noindent\textbf{Dependencies:} \hyperref[Lem_2]{Lem_2}, \hyperref[Lem_5]{Lem_5}, \hyperref[Lem_6]{Lem_6}, \hyperref[Def_11]{Def_11}

\begin{lemma*}[SpacetimeFaultDistanceLemma]
The spacetime fault-distance of the fault-tolerant gauging measurement procedure is exactly $d$ (the distance of the original code), provided:
1. The graph $G$ satisfies $h(G) \geq 1$ (Cheeger constant at least 1)
2. The number of measurement rounds satisfies $(t_o - t_i) \geq d$
\end{lemma*}

\begin{proof}
We prove both the lower bound $d_{\text{spacetime}} \geq d$ and the upper bound $d_{\text{spacetime}} \leq d$.

**Lower bound: $d_{\text{spacetime}} \geq d$**

**Case 1: Spacetime fault not equivalent to a space-only fault.**

By Lemma 6 (Lem_6), any spacetime logical fault $F$ can be decomposed as $F \sim F_{\text{space}} \cdot F_{\text{time}}$ up to spacetime stabilizers.

If $F_{\text{time}}$ is nontrivial (not a spacetime stabilizer), then by Lemma 5 (Lem_5), $F_{\text{time}}$ involves measurement faults at all time steps from $t_i$ to $t_o$. Therefore:
$$|F_{\text{time}}| \geq (t_o - t_i) \geq d$$

Since $|F| \geq |F_{\text{time}}|$ (the cleaning process doesn't reduce weight, as we'll show), we have $|F| \geq d$.

**Case 2: Spacetime fault equivalent to a space-only fault.**

By Lem_6, $F$ can be cleaned to a space-only fault $F_{\text{space}}$ at time $t_i$ using spacetime stabilizers.

The cleaning process uses stabilizers of the form: "Pauli $P$ at $t$, Pauli $P$ at $t+1$, measurement faults between." Each such stabilizer:
- Removes one Pauli at time $t$
- Adds one Pauli at time $t+1$
- Adds measurement faults

Crucially: The total number of (Pauli + initialization) faults at any fixed spatial position has constant parity throughout the cleaning. This is because each cleaning stabilizer either:
- Adds 0 net Paulis at each position (if the position isn't affected), or
- Adds 2 Paulis at one position (one at each time step), which is even.

So cleaning cannot reduce the total space weight.

The cleaned fault $F_{\text{space}}$ at time $t_i$ consists of Pauli errors on the deformed code. By Lemma 2 (Lem_2), any logical operator on the deformed code has weight at least $\min(h(G), 1) \cdot d = d$ (using $h(G) \geq 1$).

Hence $|F_{\text{space}}| \geq d$, and since cleaning doesn't reduce weight, $|F| \geq d$.

**Upper bound: $d_{\text{spacetime}} \leq d$**

We exhibit a weight-$d$ spacetime logical fault.

Let $L_{\text{orig}}$ be a minimum-weight logical operator of the original code (weight exactly $d$). Consider $L_{\text{orig}}$ applied at any single time step $t$ with $t < t_i$ or $t > t_o$ (outside the deformation region).

- This is a space-only fault of weight $d$.
- Syndrome: Empty. The operator $L_{\text{orig}}$ commutes with all stabilizers $s_j$ of the original code. Therefore, no check outcomes are affected by its application.
- Logical fault: $L_{\text{orig}}$ is a nontrivial logical operator, so it changes the encoded quantum state.

Therefore, applying $L_{\text{orig}}$ at time $t < t_i$ constitutes a spacetime logical fault of weight $d$.

**Conclusion:**

Combining bounds: $d \leq d_{\text{spacetime}} \leq d$, so $d_{\text{spacetime}} = d$.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Thm_1: GaugingMeasurement}
\label{Thm_1}

\noindent\textbf{Type:} Theorem \hfill \textbf{Formalization Order:} 30/47

\noindent\textbf{Dependencies:} \hyperref[Def_2]{Def_2}, \hyperref[Def_1]{Def_1}, \hyperref[Rem_3]{Rem_3}

\begin{theorem*}[GaugingMeasurement]
The gauging procedure defined in Algorithm 1 is equivalent to performing a projective measurement of the logical operator $L$. Specifically, applying the procedure to an initial code state $|\psi\rangle$ yields:
- A classical outcome $\sigma = \pm 1$ that equals the eigenvalue of $L$ that the state is projected onto.
- A post-measurement state $|\Psi\rangle = \frac{1}{\sqrt{2}}(\mathds{1} + \sigma L)|\psi\rangle / \|\frac{1}{\sqrt{2}}(\mathds{1} + \sigma L)|\psi\rangle\|$ (the normalized projection onto the $\sigma$-eigenspace of $L$).

The classical outcome $\sigma$ is computed as $\sigma = \prod_{v \in V_G} \varepsilon_v$ where $\varepsilon_v$ is the measurement result of $A_v$.

The procedure also outputs a Pauli byproduct operator $X_V(c')$ that may need to be applied or tracked in subsequent operations.
\end{theorem*}

\begin{proof}
We prove that the gauging measurement procedure projects onto an eigenspace of $L$ and yields the correct eigenvalue.

**Step 1: State after Gauss's law measurements.**

Starting with initial code state $|\psi\rangle$ and edge qubits initialized to $|0\rangle_E = |0\rangle^{\otimes E_G}$, we measure all Gauss's law operators $A_v = X_v \prod_{e \ni v} X_e$.

Let $\varepsilon_v = \pm 1$ be the measurement outcome for $A_v$. By the measurement postulate, after measuring $A_v$ with outcome $\varepsilon_v$, the state is projected by $\frac{1}{2}(\mathds{1} + \varepsilon_v A_v)$.

After measuring all $A_v$ operators, the post-measurement state (unnormalized) is:
$$\prod_v \frac{1}{2}(\mathds{1} + \varepsilon_v A_v) |\psi\rangle |0\rangle_E$$

**Step 2: Ungauging step.**

We measure $Z_e$ on each edge qubit with outcome $z_e = \pm 1$ (equivalently $z_e \in \{0,1\}$ where $z_e = 0$ for outcome $+1$), then discard the edge qubits.

The state becomes (up to normalization):
$$\langle z_e|_E \prod_v \frac{1}{2}(\mathds{1} + \varepsilon_v A_v) |\psi\rangle |0\rangle_E$$
where $\langle z_e|_E = \bigotimes_e \langle z_e|_e$ and $|z_e\rangle_e$ is the computational basis state with $Z_e|z_e\rangle_e = (-1)^{z_e}|z_e\rangle_e$.

**Step 3: Expand the projection.**

Define notation:
- $C^0(G, \mathbb{Z}_2)$ = set of all $\mathbb{Z}_2$-valued 0-cochains on $G$ (binary vectors on vertices)
- For $c \in C^0(G, \mathbb{Z}_2)$: $\varepsilon(c) = \prod_v \varepsilon_v^{c_v}$ (product of outcomes where $c_v = 1$)
- $X_V(c) = \prod_v X_v^{c_v}$ (product of $X$ on vertices where $c_v = 1$)
- $X_E(\delta c) = \prod_e X_e^{(\delta c)_e}$ where $\delta$ is the coboundary map

Expanding the product of projectors using the identity $\frac{1}{2}(\mathds{1} + \varepsilon A) = \frac{1}{2}\sum_{a \in \{0,1\}} \varepsilon^a A^a$:

$$\prod_v \frac{1}{2}(\mathds{1} + \varepsilon_v A_v) = \frac{1}{2^{|V_G|}} \sum_{c \in C^0(G, \mathbb{Z}_2)} \prod_v \varepsilon_v^{c_v} \prod_v A_v^{c_v}$$

Now, $\prod_v A_v^{c_v} = \prod_v (X_v \prod_{e \ni v} X_e)^{c_v}$.

The vertex part is: $\prod_v X_v^{c_v} = X_V(c)$.

The edge part: For edge $e = \{u, w\}$, the factor $X_e$ appears with exponent $c_u + c_w = (\delta c)_e$ (the coboundary). So:
$$\prod_v \prod_{e \ni v} X_e^{c_v} = \prod_e X_e^{(\delta c)_e} = X_E(\delta c)$$

Therefore:
$$\prod_v \frac{1}{2}(\mathds{1} + \varepsilon_v A_v) = \frac{1}{2^{|V_G|}} \sum_{c \in C^0(G, \mathbb{Z}_2)} \varepsilon(c) X_V(c) X_E(\delta c)$$

**Step 4: Apply $Z$ measurement constraint.**

We compute $\langle z_e|_E X_E(\delta c) |0\rangle_E$.

- $X_E(\delta c)|0\rangle_E = |\delta c\rangle_E$ (flips qubits where $(\delta c)_e = 1$).
- $\langle z_e|_E |\delta c\rangle_E = 1$ if $z_e = (\delta c)_e$ for all edges, else $0$.

So the amplitude is nonzero only when $\delta c = z$ (the edge outcomes match the coboundary). The state restricts to:
$$\frac{1}{2^{|V_G|}} \sum_{c : \delta c = z} \varepsilon(c) X_V(c) |\psi\rangle$$

**Step 5: Use cocycle structure.**

Fix any $c'$ with $\delta c' = z$. Then $\{c : \delta c = z\} = \{c' + c_0 : c_0 \in \ker(\delta)\}$.

For a connected graph $G$, the kernel $\ker(\delta)$ has exactly two elements:
- $\mathbf{0}$: the zero cochain (no vertices)
- $\mathbf{1}$: the all-ones cochain (all vertices)

This is because $\delta c = 0$ means $\sum_{v \in e} c_v = 0$ for all edges, i.e., every edge has an even number of endpoints in $c$. For a connected graph, this forces $c$ to be constant (all 0 or all 1).

So the sum has exactly two terms:
$$\frac{1}{2^{|V_G|}} \left[ \varepsilon(c') X_V(c') + \varepsilon(c' + \mathbf{1}) X_V(c' + \mathbf{1}) \right] |\psi\rangle$$

**Step 6: Simplify using $L$.**

Compute the second term:
- $\varepsilon(c' + \mathbf{1}) = \prod_v \varepsilon_v^{c'_v + 1} = \prod_v \varepsilon_v^{c'_v} \cdot \prod_v \varepsilon_v = \varepsilon(c') \cdot \prod_v \varepsilon_v$
- $X_V(c' + \mathbf{1}) = \prod_v X_v^{c'_v + 1} = \prod_v X_v^{c'_v} \cdot \prod_v X_v = X_V(c') \cdot L$

Define $\sigma = \prod_v \varepsilon_v$. The state becomes:
$$\frac{1}{2^{|V_G|}} \varepsilon(c') X_V(c') (\mathds{1} + \sigma L) |\psi\rangle$$

Up to normalization and the global phase $\varepsilon(c')$, this is:
$$X_V(c') \frac{1}{2}(\mathds{1} + \sigma L)|\psi\rangle$$

**Step 7: Interpret the result.**

The operator $\frac{1}{2}(\mathds{1} + \sigma L)$ is the projector onto the $\sigma$-eigenspace of $L$. This is because:
- $L^2 = \mathds{1}$ (Pauli operator squares to identity)
- For eigenvalue $\sigma$: $L|\psi_\sigma\rangle = \sigma|\psi_\sigma\rangle$
- Check: $\frac{1}{2}(\mathds{1} + \sigma L)|\psi_\sigma\rangle = \frac{1}{2}(1 + \sigma^2)|\psi_\sigma\rangle = |\psi_\sigma\rangle$ ✓
- For eigenvalue $-\sigma$: $\frac{1}{2}(\mathds{1} + \sigma L)|\psi_{-\sigma}\rangle = \frac{1}{2}(1 - 1)|\psi_{-\sigma}\rangle = 0$ ✓

The outcome $\sigma = \prod_v \varepsilon_v$ is the measured eigenvalue.

The Pauli operator $X_V(c')$ is the byproduct operator determined by the edge measurement outcomes. It can be computed from the $z_e$ outcomes: finding any $c'$ with $\delta c' = z$ (e.g., via a spanning tree algorithm).

This completes the proof that the gauging procedure is equivalent to projective measurement of $L$.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Thm_2: FaultTolerance}
\label{Thm_2}

\noindent\textbf{Type:} Theorem \hfill \textbf{Formalization Order:} 31/47

\noindent\textbf{Dependencies:} \hyperref[Lem_2]{Lem_2}, \hyperref[Lem_5]{Lem_5}, \hyperref[Lem_6]{Lem_6}, \hyperref[Rem_5]{Rem_5}, \hyperref[Def_11]{Def_11}

\begin{theorem*}[FaultTolerance]
The fault-tolerant implementation of Algorithm 1 with a suitable graph $G$ has spacetime fault-distance $d$, where $d$ is the distance of the original code. Specifically, if:
1. The graph $G$ satisfies the Cheeger constant condition $h(G) \geq 1$, and
2. The number of measurement rounds satisfies $(t_o - t_i) \geq d$,

then any spacetime logical fault (a fault pattern causing a logical error without triggering any detector) has weight at least $d$.
\end{theorem*}

\begin{proof}
The proof combines several lemmas. We show that the spacetime fault-distance is at least $d$ by analyzing space-like and time-like logical faults separately.

**Step 1: Decomposition of spacetime faults (by Lem_6).**

By the decoupling lemma (Lem_6), any spacetime logical fault $F$ is equivalent (up to spacetime stabilizers) to the product of a space-like logical fault $F_{\text{space}}$ and a time-like logical fault $F_{\text{time}}$:
$$F \sim F_{\text{space}} \cdot F_{\text{time}}$$

This means we can analyze these two types separately and combine the bounds.

**Step 2: Time fault-distance (by Lem_5).**

By the time fault-distance lemma (Lem_5), any time-like logical fault (consisting only of measurement and initialization errors) has weight at least $(t_o - t_i)$.

Since we require $(t_o - t_i) \geq d$, any nontrivial $F_{\text{time}}$ has weight at least $d$.

**Step 3: Space fault-distance (by Lem_2).**

By the space distance lemma (Lem_2), any logical operator in the deformed code has weight at least $\min(h(G), 1) \cdot d$.

Since we require $h(G) \geq 1$, this gives $\min(h(G), 1) = 1$, so any space-like logical fault has weight at least $d$.

**Step 4: Combined bound.**

Consider an arbitrary spacetime logical fault $F$. By Step 1, $F \sim F_{\text{space}} \cdot F_{\text{time}}$ up to spacetime stabilizers.

**Case A: $F_{\text{time}}$ is non-trivial (not a spacetime stabilizer).**

Then by Step 2, $|F_{\text{time}}| \geq d$.

The cleaning process (from $F$ to $F_{\text{space}} \cdot F_{\text{time}}$) uses spacetime stabilizers that preserve the parity of space and initialization faults at each spatial position. Therefore, $|F| \geq |F_{\text{time}}| \geq d$.

**Case B: $F_{\text{time}}$ is trivial.**

Then $F$ is equivalent to $F_{\text{space}}$ alone. By Step 3, $|F_{\text{space}}| \geq d$.

The equivalence via spacetime stabilizers cannot reduce the weight below $d$ because each spacetime stabilizer preserves the parity of space and initialization faults along each timeline at a fixed position. Specifically:
- Moving a Pauli from time $t$ to $t+1$ doesn't reduce total space weight.
- Cancelling an init fault with an $X_e$ adds back 1 to space weight.

So $|F| \geq |F_{\text{space}}| \geq d$.

**Step 5: Conclusion.**

In both cases, $|F| \geq d$. Therefore, the spacetime fault-distance is at least $d$:
$$d_{\text{spacetime}} \geq d$$

**Matching upper bound:**

The original code distance provides a matching upper bound. Let $L_{\text{orig}}$ be a weight-$d$ logical operator of the original code. Applying $L_{\text{orig}}$ at any single time step $t < t_i$ (in the original code, before gauging):
- Is a space-only fault of weight $d$.
- Has empty syndrome (commutes with all $s_j$).
- Is a logical fault (applies a nontrivial logical operation).

Therefore, $d_{\text{spacetime}} \leq d$.

**Final result:**

Combining: $d_{\text{spacetime}} = d$.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Cor_1: OverheadBound}
\label{Cor_1}

\noindent\textbf{Type:} Corollary \hfill \textbf{Formalization Order:} 32/47

\noindent\textbf{Dependencies:} \hyperref[Rem_9]{Rem_9}, \hyperref[Def_6]{Def_6}

\begin{corollary*}[OverheadBound]
The gauging measurement procedure for measuring a logical operator $L$ of weight $W = |\text{supp}(L)|$ can be implemented with qubit overhead $O(W \log^2 W)$. Specifically, the number of additional auxiliary qubits required is at most $c \cdot W \log^2 W$ for some universal constant $c > 0$.
\end{corollary*}

\begin{proof}
We analyze the overhead from each component of the construction described in Rem_9.

**Step 1: Count qubits in graph $G_0$.**

The initial graph $G_0$ has:
- $W$ vertices (qubits in support of $L$).
- Edges from the perfect matching step: For each check overlapping $L$, we add edges matching pairs of vertices in the $Z$-type support. Since each check has bounded degree (LDPC property) and each vertex appears in a bounded number of checks, the total number of matching edges is $O(W)$.
- Edges from the expander step: We add edges until $h(G_0) \geq 1$. Constant-degree expanders exist with $O(W)$ vertices and $O(W)$ edges. So this step adds $O(W)$ edges.

Total edges in $G_0$: $O(W)$.
Each edge introduces one auxiliary (gauge) qubit.
So $G_0$ contributes $O(W)$ auxiliary qubits.

**Step 2: Count qubits in cycle sparsification.**

By Rem_9 and the Freedman-Hastings decongestion lemma:
- Number of layers: $R = O(\log^2 W)$.
- Each layer $i$ (for $i = 1, \ldots, R$) contains:
  - A copy of $G_0$ on dummy vertices: $O(W)$ edges.
  - Cellulation edges for cycles assigned to layer $i$: $O(W)$ edges (since total cycle edge-length is $O(W)$).
  - Inter-layer edges connecting layer $i-1$ to layer $i$: $W$ edges.

Total qubits from layers:
- Inter-layer edge qubits: $R \cdot W = O(W \log^2 W)$.
- Intra-layer edge qubits (copies of $G_0$): $R \cdot O(W) = O(W \log^2 W)$.
- Cellulation edge qubits: Total $O(W)$ across all layers (each cycle is cellulated once).

**Step 3: Dummy vertices don't require physical qubits.**

Dummy vertices are initialized in $|+\rangle$ and measuring $X$ always gives $+1$. In the algorithm, these can be replaced by classical $+1$ values. Only the edge qubits attached to dummy vertices are physical qubits.

**Step 4: Final count.**

Total auxiliary qubits:
- Layer 0 edge qubits: $O(W)$
- Inter-layer edge qubits: $O(W \log^2 W)$
- Layers 1 through $R$ intra-layer edge qubits: $O(W \log^2 W)$
- Cellulation edges: $O(W)$

Grand total: $O(W \log^2 W)$.

This is a significant improvement over the $O(Wd)$ overhead of previous schemes (e.g., Cohen et al.) when $d > \log^2 W$, which is the case for good qLDPC codes with $d = \Theta(n)$ and logical operators of weight $W = O(n)$.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Cor_2: CheegerOptimality}
\label{Cor_2}

\noindent\textbf{Type:} Corollary \hfill \textbf{Formalization Order:} 33/47

\noindent\textbf{Dependencies:} \hyperref[Lem_2]{Lem_2}

\begin{corollary*}[CheegerOptimality]
Choosing a graph $G$ with Cheeger constant $h(G) = 1$ is optimal in the following sense:
1. The deformed code distance satisfies $d^* = d$ (no distance reduction).
2. A Cheeger constant larger than 1 does not further improve the distance.
3. A Cheeger constant smaller than 1 causes distance reduction by factor $h(G)$.
\end{corollary*}

\begin{proof}
This follows directly from Lemma 2 (Lem_2), which establishes $d^* \geq \min(h(G), 1) \cdot d$.

**Part 1: $h(G) = 1$ gives $d^* = d$.**

*Lower bound:* From Lem_2: $d^* \geq \min(1, 1) \cdot d = d$.

*Upper bound:* The deformed code contains the original code qubits (as vertex qubits). Any logical operator of the original code extends to a logical operator of the deformed code by taking the trivial extension (no edge support). Specifically, for a logical $\ell$ of the original code with $|\ell| = d$, the operator $\ell \otimes I_E$ (acting as $\ell$ on vertices and identity on edges) is a logical of the deformed code with weight $d$.

Therefore, $d^* \leq d$.

*Combining:* $d^* = d$.

**Part 2: $h(G) > 1$ doesn't help.**

From Lem_2: $d^* \geq \min(h(G), 1) \cdot d = d$ for any $h(G) \geq 1$.

The bound doesn't improve beyond $d$ because:
- Logicals can be "cleaned" onto the original vertices by multiplying with $A_v$ stabilizers (as shown in Lem_2).
- A logical supported only on original vertices (no edge qubits) has its weight unchanged from the original code.
- The minimum with 1 in the formula reflects that we can always achieve a logical with no edge support, so increasing $h(G)$ beyond 1 doesn't help.

**Part 3: $h(G) < 1$ causes reduction.**

*Lower bound:* From Lem_2: $d^* \geq h(G) \cdot d$ when $h(G) < 1$.

*This bound can be achieved:* Take a minimum vertex cut $S$ in $G$ achieving the Cheeger constant: $|\partial S| = h(G) \cdot |S|$ with $|S| \leq |V_G|/2$.

Consider a logical operator of the original code that has X-support on vertices in $S$. After cleaning (multiplying by $\prod_{v \in S} A_v$), the X-support moves to the edges $\partial S$. The weight is:
$$|\partial S| = h(G) \cdot |S|$$

If $|S|$ can be chosen so that the original logical has weight $d$ on $S$, then the cleaned logical has weight $h(G) \cdot d$ on edges, which could be less than $d$.

More precisely, the proof of Lem_2 shows that converting from $\overline{L}$ (supported on vertices) to $L'$ (supported on edges) changes weight by factor at least $h(G)$. When $h(G) < 1$, this can reduce the weight.

**Conclusion:**

$h(G) = 1$ is optimal: it achieves $d^* = d$ with no distance reduction, and increasing $h(G)$ beyond 1 provides no additional benefit for the distance guarantee.
\end{proof}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_11: InitialFinalBoundaryConditions}
\label{Rem_11}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 34/47

\noindent\textbf{Dependencies:} \hyperref[Def_12]{Def_12}

\begin{remark*}[InitialFinalBoundaryConditions]
Following standard practice, we use the convention that the initial and final round of stabilizer measurements are perfect. This is to facilitate clean statements of our results and should not be taken literally. The justification for why this convention does not fundamentally change results is due to the $d$ rounds of error correction in the original code before and after the gauging measurement. This ensures that any error process involving both the gauging measurement and the initial or final boundary condition must have distance greater than $d$. In practice, the gauging measurement is intended to be one component of a larger fault-tolerant quantum computation which determines the appropriate realistic boundary conditions to use.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_12: NoncommutingOperators}
\label{Rem_12}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 35/47

\noindent\textbf{Dependencies:} \hyperref[Def_4]{Def_4}

\begin{remark*}[NoncommutingOperators]
There is no deformed version of a Pauli operator $P$ that does not commute with the logical $L$. This is because there is no way to multiply such a $P$ with stabilizers $Z_e$ and $s_j$ to make it commute with all the Gauss's law operators $A_v$ that are measured to implement the code deformation. Specifically, if $P$ anticommutes with $L$, then $|\mathcal{S}_Z \cap V_G|$ is odd (where $\mathcal{S}_Z$ is the Z-type support of $P$), and no edge-path $\gamma$ with $\partial \gamma = \mathcal{S}_Z \cap V_G$ exists because a path boundary always has even cardinality.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_13: FluxCheckMeasurementFrequency}
\label{Rem_13}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 36/47

\noindent\textbf{Dependencies:} \hyperref[Def_3]{Def_3}, \hyperref[Thm_2]{Thm_2}

\begin{remark*}[FluxCheckMeasurementFrequency]
The scaling of the fault distance holds even if the $B_p$ flux checks are measured much less often than the $A_v$ and $\tilde{s}_j$ checks. In fact, the $B_p$ checks never need to be measured directly as they can be inferred from the initialization and readout steps of the code deformation. While this is appealing for cases where the $B_p$ checks have high weight, it results in large detector cells and hence the code is not expected to have a threshold without further modifications. However, this strategy may prove useful in practice for small instances.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_14: Generalizations}
\label{Rem_14}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 37/47

\noindent\textbf{Dependencies:} \hyperref[Thm_1]{Thm_1}

\begin{remark*}[Generalizations]
The gauging measurement procedure generalizes beyond Pauli stabilizer codes:

1. **Finite group representations**: The procedure can be applied to any representation of a finite group by operators that have a tensor product factorization. The representation need not form the logical operators of a quantum error-correcting code.

2. **Non-Pauli operators**: The gauging measurement can measure non-Pauli operators, whose measurement can produce magic states. An example is the measurement of Clifford operators in a topological code.

3. **Qudit systems**: The procedure extends to qudit systems with $d > 2$ levels per site.

4. **Nonabelian groups**: The generalization extends to nonabelian groups. However, for nonabelian groups, measuring the charge locally does not fix a definite global charge (unlike the abelian case where local measurements determine the global outcome).
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_15: HypergraphGeneralization}
\label{Rem_15}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 38/47

\noindent\textbf{Dependencies:} \hyperref[Def_2]{Def_2}

\begin{remark*}[HypergraphGeneralization]
The gauging measurement procedure can be generalized by replacing the graph $G$ with a **hypergraph** to measure multiple operators simultaneously.

**Setup**: Consider an abelian group of operators describable as the $X$-type operators that commute with an auxiliary set of $k$-local $Z$-type checks. Using the stabilizer formalism, this group can be equivalently formulated as the kernel of a sparse linear map over $\mathbb{F}_2$.

**Procedure**: For qubits, this is equivalent to replacing the graph $G$ with a hypergraph. The generalized gauging procedure performs a code deformation by:
1. Introducing a qubit for each hyperedge
2. Measuring into new Gauss's law checks $A_v$ given by the product of $X$ on a vertex and the adjacent hyperedges: $A_v = X_v \prod_{e \ni v, e \in \text{hyperedges}} X_e$

**Application**: This allows measuring any abelian group of commuting logical operators that can be characterized as the kernel of a sparse parity-check matrix.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_16: PracticalMeasurementRounds}
\label{Rem_16}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 39/47

\noindent\textbf{Dependencies:} \hyperref[Thm_2]{Thm_2}

\begin{remark*}[PracticalMeasurementRounds]
The $d$ rounds of quantum error correction in the original code before and after the gauging measurement are required for the proof of fault-tolerance but are overkill in practice.

In a full fault-tolerant computation, the number of rounds required before and after a gauging measurement depends on the surrounding operations:
- If the gauging measurement occurs in the middle of a large computation, a constant number of rounds before and after are expected to be sufficient to ensure fault tolerance.
- However, this choice affects the effective distance and threshold depending on the surrounding operations.

The theoretical requirement of $d$ rounds serves as a worst-case guarantee but practical implementations may use fewer rounds based on the specific computation context.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_17: CircuitImplementationFaultTolerance}
\label{Rem_17}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 40/47

\noindent\textbf{Dependencies:} \hyperref[Rem_6]{Rem_6}, \hyperref[Thm_2]{Thm_2}

\begin{remark*}[CircuitImplementationFaultTolerance]
The circuit implementation introduced in Rem_6 leads to a different but closely related fault-tolerant implementation where the vertex qubits are decoupled and can be discarded during the code deformation.

**Potential issue**: This alternative implementation can lead to a reduction in the code distance by a constant multiple factor.

**Solution**: The distance reduction can be avoided by adding an extra dummy vertex to divide each edge into a pair of edges. Specifically, for each edge $e = \{u, v\}$ in $G$:
1. Add a dummy vertex $w$
2. Replace edge $e$ with two edges $\{u, w\}$ and $\{w, v\}$

This modification preserves the fault-distance at the cost of doubling the number of edge qubits.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_18: LatticeSurgeryAsGauging}
\label{Rem_18}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 41/47

\noindent\textbf{Dependencies:} \hyperref[Rem_8]{Rem_8}, \hyperref[Thm_1]{Thm_1}

\begin{remark*}[LatticeSurgeryAsGauging]
**Lattice surgery is a special case of gauging measurement.** The gauging measurement can be interpreted as a direct generalization of lattice surgery for surface codes.

**Example**: Consider measuring the logical operator $\overline{X}_1 \otimes \overline{X}_2$ supported on the right and left edges of a pair of equally sized surface code blocks. Applying the gauging measurement with a graph $G$ chosen as a **ladder** joining the edge qubits of the surface codes results in:
1. A deformed code that is again a surface code on the union of the two patches
2. The final step of measuring out individual edge qubits matches conventional lattice surgery

**Non-adjacent patches**: To implement lattice surgery between surface codes that are not directly adjacent, apply the gauging procedure with a graph that includes a grid of dummy vertices between the two edges.

**Generalization**: This procedure extends to measure any pair of matching logical $X$ operators on a pair of code blocks, where each logical has the same choice of graph $G$. The graph $G$ is allowed to have expansion $h(G) < 1$ as long as it satisfies the path-length and cycle-weight desiderata. Additional 'bridge' edges connect vertices between the two copies of $G$.

**Insight**: The expansion condition $h(G) \geq 1$ is overkill in some settings; expansion appears to be required only for subsets of qubits relevant to the logical operators being measured.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_19: ShorStyleMeasurementAsGauging}
\label{Rem_19}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 42/47

\noindent\textbf{Dependencies:} \hyperref[Thm_1]{Thm_1}, \hyperref[Rem_2]{Rem_2}

\begin{remark*}[ShorStyleMeasurementAsGauging]
**Shor-style logical measurement is a special case of gauging measurement.**

**Shor-style measurement recap**: The standard Shor-style measurement involves:
1. Preparing an auxiliary GHZ state $|\text{GHZ}\rangle = \frac{1}{\sqrt{2}}(|0\rangle^{\otimes W} + |1\rangle^{\otimes W})$ where $W = |\text{supp}(L)|$
2. Entangling it to a code block via transversal $CX$ gates between the auxiliary qubits and the support of the $X$ logical $L$
3. Measuring $X$ on each auxiliary qubit and discarding them

**Gauging formulation**: The same measurement can be performed using the gauging procedure with the following graph structure:
1. For each qubit $v$ in the support of $L$, create a dummy vertex $u_v$ connected to $v$ by an edge
2. Connect all dummy vertices $\{u_v\}$ via a connected graph (e.g., a path or star)

**Correspondence**: If we perform the gauging measurement where the edges of the connected graph on dummy vertices are measured first, the resulting intermediate state corresponds to a GHZ state entangled with the support of $L$. This is equivalent to Shor-style measurement with the final $X$ measurements commuted backwards through the $CX$ gates.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_20: CohenSchemeAsGauging}
\label{Rem_20}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 43/47

\noindent\textbf{Dependencies:} \hyperref[Rem_15]{Rem_15}, \hyperref[Thm_1]{Thm_1}

\begin{remark*}[CohenSchemeAsGauging]
**The Cohen et al. scheme for logical measurement can be recovered as a hypergraph gauging measurement.**

**Cohen et al. scheme setup**: Consider the restriction of the $Z$-type checks to the support of an irreducible $X$ logical $L$. This defines a hypergraph of $Z$ constraints with the only nontrivial element in the kernel being the logical operator $L$.

**Recovery via gauging**:
1. Add $d$ layers of dummy vertices for each qubit in $\text{supp}(L)$
2. Connect the $d$ copies of each vertex via a line graph (chain)
3. Join the vertices in each layer via a copy of the same underlying hypergraph

Applying the generalized hypergraph gauging procedure to this construction exactly reproduces the Cohen et al. measurement scheme.

**Cross et al. modification**: The scheme from Cross et al. can similarly be recovered by using fewer than $d$ layers of dummy vertices.

**Product measurement**: The procedures for joining ancilla systems designed for irreducible logicals to measure their products can be captured as a gauging measurement by adding edges between the graphs corresponding to the individual ancilla systems.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_21: CSSCodeInitializationAsGauging}
\label{Rem_21}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 44/47

\noindent\textbf{Dependencies:} \hyperref[Rem_15]{Rem_15}, \hyperref[Thm_1]{Thm_1}

\begin{remark*}[CSSCodeInitializationAsGauging]
**Standard CSS code initialization can be implemented via hypergraph gauging.**

**Standard initialization**: A CSS code is typically initialized by preparing $|0\rangle^{\otimes n}$ and measuring all $X$-type checks.

**Gauging formulation**:
1. Start with a trivial code having one dummy vertex for each $X$-type check of the target CSS code
2. Perform the generalized gauging measurement using the hypergraph corresponding to the $Z$-type checks of the CSS code
3. The ungauging step performs readout measurement of $Z$ on all qubits

**Steane-style measurement via gauging**: The state preparation and readout gauging procedure can be combined with another gauging measurement to implement a Steane-style measurement of a stabilizer group:
1. Perform state preparation of an ancilla code block via gauging as described above
2. Perform a gauging measurement of $XX$ on pairs of matching qubits between the data code block and the ancilla code block
3. Perform the ungauging step to read out $Z$ on all ancilla qubits

This connection shows that many existing fault-tolerant gadgets can be unified under the gauging framework.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_13: BivariateBicycleCode}
\label{Def_13}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 45/47

\begin{definition*}[BivariateBicycleCode]
A **Bivariate Bicycle (BB) code** is a CSS code defined as follows:

**Setup**: Let $\ell, m$ be positive integers. Define:
- $I_r$: the $r \times r$ identity matrix
- $C_r$: the cyclic permutation matrix of $r$ items, satisfying $\langle i|C_r = \langle (i+1) \mod r|$ for all $i$
- $x = C_\ell \otimes I_m$ (cyclic shift in the first coordinate)
- $y = I_\ell \otimes C_m$ (cyclic shift in the second coordinate)

These matrices satisfy $x^\ell = y^m = I_{\ell m}$ and $x^\top x = y^\top y = I_{\ell m}$.

**Qubits**: The code uses $n = 2\ell m$ physical qubits divided into:
- $\ell m$ **left** ($L$) qubits
- $\ell m$ **right** ($R$) qubits

**Parity check matrices**: Given polynomials $A, B \in \mathbb{F}_2[x, y]$ (polynomials in the matrices $x$ and $y$), the parity check matrices are:
$$H_X = [A | B], \quad H_Z = [B^\top | A^\top]$$
where $A^\top = A(x^{-1}, y^{-1})$ and likewise for $B^\top$.

**Checks**: There are $\ell m$ $X$ checks and $\ell m$ $Z$ checks in this generating set, though only $(n-k)/2$ checks of either type are independent for a code encoding $k$ qubits.

**Labeling convention**: The $X$ checks, $Z$ checks, $L$ qubits, and $R$ qubits are each in 1-1 correspondence with elements of $\mathcal{M} = \{x^a y^b : a, b \in \mathbb{Z}\}$. We write $(\alpha, T)$ for $\alpha \in \mathcal{M}$ and $T \in \{X, Z, L, R\}$ to label individual checks or qubits.

**Pauli notation**: An $X$-type Pauli acting on left qubits $(p, L)$ and right qubits $(q, R)$ for polynomials $p, q$ is written $X(p, q)$. Similarly for $Z$-type: $Z(p, q)$.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Def_14: GrossCode}
\label{Def_14}

\noindent\textbf{Type:} Definition \hfill \textbf{Formalization Order:} 46/47

\noindent\textbf{Dependencies:} \hyperref[Def_13]{Def_13}

\begin{definition*}[GrossCode]
The **Gross code** is a specific $[[144, 12, 12]]$ Bivariate Bicycle code, so named because a 'gross' is a dozen dozens (144).

**Parameters**: $\ell = 12$, $m = 6$, giving $n = 2 \cdot 12 \cdot 6 = 144$ qubits.

**Polynomials**:
$$A = x^3 + y^2 + y, \quad B = y^3 + x^2 + x$$

**Logical operators**: A convenient basis of logical operators uses the polynomials:
$$f = 1 + x + x^2 + x^3 + x^6 + x^7 + x^8 + x^9 + (x + x^5 + x^7 + x^{11})y^3$$
$$g = x + x^2 y + (1 + x)y^2 + x^2 y^3 + y^4$$
$$h = 1 + (1 + x)y + y^2 + (1 + x)y^3$$

Then for any monomials $\alpha, \beta \in \mathcal{M}$:
- $\overline{X}_\alpha = X(\alpha f, 0)$ are $X$-type logical operators of weight 12
- $\overline{X}'_\beta = X(\beta g, \beta h)$ are $X$-type logical operators
- $\overline{Z}_\beta = Z(\beta h^\top, \beta g^\top)$ are $Z$-type logical operators  
- $\overline{Z}'_\alpha = Z(0, \alpha f^\top)$ are $Z$-type logical operators

**Symmetry**: The symmetry in the BB code construction means that if gauging measurements are constructed for $\overline{X}_\alpha$ and $\overline{X}'_\beta$, the same Tanner graph connectivity works for $\overline{Z}'_\alpha$ and $\overline{Z}_\beta$.
\end{definition*}

\vspace{1em}
\hrule
\vspace{1em}

\subsection{Rem_22: GrossCodeGaugingExample}
\label{Rem_22}

\noindent\textbf{Type:} Remark \hfill \textbf{Formalization Order:} 47/47

\noindent\textbf{Dependencies:} \hyperref[Def_14]{Def_14}, \hyperref[Thm_1]{Thm_1}, \hyperref[Lem_1]{Lem_1}

\begin{remark*}[GrossCodeGaugingExample]
The gauging measurement for $\overline{X}_\alpha$ in the Gross code provides a concrete example demonstrating the efficiency of the gauging approach.

**Goal**: Measure $\overline{X}_\alpha = X(\alpha f, 0)$ while keeping all new checks and qubits at Tanner graph degree at most 6 (the 12 qubits in $\overline{X}_\alpha$ and 18 adjacent $Z$ checks will become degree 7).

**Graph construction**:
1. **Vertices**: The 12 monomials in $f$ correspond to the 12 vertices of $G$
2. **Initial edges**: Connect vertices $\gamma, \delta \in f$ if qubits $(\gamma, L)$ and $(\delta, L)$ participate in the same $Z$ check, i.e., if $\gamma = B_i^\top B_j \delta$ for some $i, j \in \{1, 2, 3\}$. This gives 18 edges.
3. **Expansion edges**: Add 4 additional edges to achieve distance 12: $(x^2, x^5 y^3)$, $(x^2, x^6)$, $(x^5 y^3, x^{11} y^3)$, $(x^7 y^3, x^{11} y^3)$

**Cycle basis**: With 12 vertices and 22 edges, $G$ has $22 - 12 + 1 = 11$ independent cycles. Due to redundancy in the BB code's $Z$ checks (4 redundant cycles), only $11 - 4 = 7$ independent $B_p$ checks are needed.

**Overhead summary**:
- 12 new $X$ checks (Gauss's law operators $A_v$)
- 7 new $Z$ checks (flux operators $B_p$)  
- 22 new qubits (edge qubits)
- **Total additional elements: 41**

This is significantly more efficient than the $O(Wd) = O(12 \cdot 12) = O(144)$ overhead of previous schemes.
\end{remark*}

\vspace{1em}
\hrule
\vspace{1em}


\newpage
\section{Summary by Type}

\begin{itemize}
  \item \textbf{Corollarys:} 2
  \item \textbf{Definitions:} 14
  \item \textbf{Lemmas:} 7
  \item \textbf{Remarks:} 22
  \item \textbf{Theorems:} 2
  \item \textbf{Total:} 47
\end{itemize}

\end{document}
