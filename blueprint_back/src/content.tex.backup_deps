%==============================================================================
% Auto-generated by autoinformalization
% Library: gauging_ldpc
% Generated: 2026-02-02 01:38:20
%==============================================================================


\chapter{Vertex Set Partition}
\begin{remark}[Vertex Set Partition]
\label{rem:vertex_set_partition}
\lean{GaugingLDPC.VertexPartition}
\leanok

Let $\mathcal{G} = (\mathcal{G}_0, \mathcal{G}_1, \mathcal{G}_2)$ be a cell complex (gauging graph) where $\mathcal{G}_0$ is the set of vertices, $\mathcal{G}_1$ is the set of edges, and $\mathcal{G}_2$ is the set of 2-cells (plaquettes). Let $\mathbb{F}_w$ be the finite field with $w$ elements. For each vertex $v \in \mathcal{G}_0$, we define $\Sigma(v)$ to be a subset of matter qudits of the original quantum error-correcting code. The collection $\{\Sigma(v)\}_{v \in \mathcal{G}_0}$ forms a partition of the matter qudits, meaning:

\begin{enumerate}
    \item \textbf{Disjointness}: $\Sigma(v) \cap \Sigma(w) = \emptyset$ for all $v \neq w$ in $\mathcal{G}_0$.
    \item \textbf{Covering}: $\bigcup_{v \in \mathcal{G}_0} \Sigma(v)$ equals the set of all matter qudits.
\end{enumerate}
\end{remark}

\begin{definition}[Cell Complex]
\label{def:cell_complex}
\lean{GaugingLDPC.CellComplex}
\leanok

A \emph{cell complex} (gauging graph) is a structure $\mathcal{G} = (\mathcal{G}_0, \mathcal{G}_1, \mathcal{G}_2)$ consisting of:
\begin{itemize}
    \item $\mathcal{G}_0$: the set of 0-cells (vertices),
    \item $\mathcal{G}_1$: the set of 1-cells (edges),
    \item $\mathcal{G}_2$: the set of 2-cells (plaquettes),
\end{itemize}
where the vertex set is finite with decidable equality.
\end{definition}

\begin{definition}[Matter Qudits]
\label{def:matter_qudits}
\lean{GaugingLDPC.MatterQudits}
\leanok

The type of \emph{matter qudits} in the quantum error-correcting code is a structure consisting of a finite type $Q$ of qudit indices with decidable equality.
\end{definition}

\begin{definition}[Vertex Partition]
\label{def:vertex_partition}
\lean{GaugingLDPC.VertexPartition}
\leanok
\uses{def:cell_complex, def:matter_qudits}

A \emph{vertex partition} assigns to each vertex $v \in \mathcal{G}_0$ a subset $\Sigma(v)$ of matter qudits such that the collection $\{\Sigma(v)\}_{v \in \mathcal{G}_0}$ forms a partition of the matter qudits. Formally, it consists of:
\begin{itemize}
    \item A function $\Sigma : \mathcal{G}_0 \to \mathcal{P}(M)$ sending each vertex to its set of matter qudits,
    \item An underlying indexed partition structure ensuring the partition properties hold.
\end{itemize}
\end{definition}

\begin{theorem}[Pairwise Disjointness]
\label{thm:pairwise_disjoint}
\lean{GaugingLDPC.VertexPartition.pairwiseDisjoint}
\leanok
\uses{def:vertex_partition}

For distinct vertices $v \neq w$, we have $\Sigma(v)$ and $\Sigma(w)$ are disjoint: $\Sigma(v) \cap \Sigma(w) = \emptyset$.
\end{theorem}

\begin{proof}
\leanok

This follows directly from the disjoint property of the underlying indexed partition structure.
\end{proof}

\begin{theorem}[Intersection is Empty]
\label{thm:inter_eq_empty}
\lean{GaugingLDPC.VertexPartition.inter_eq_empty}
\leanok
\uses{thm:pairwise_disjoint}

For distinct vertices $v \neq w$ in $\mathcal{G}_0$, we have $\Sigma(v) \cap \Sigma(w) = \emptyset$.
\end{theorem}

\begin{proof}
\leanok
\uses{thm:pairwise_disjoint}
Let $v \neq w$. By the pairwise disjointness theorem, $\Sigma(v)$ and $\Sigma(w)$ are disjoint. The result follows from the equivalence between disjointness and having empty intersection.
\end{proof}

\begin{theorem}[Covering Property]
\label{thm:i_union_eq_univ}
\lean{GaugingLDPC.VertexPartition.iUnion_eq_univ}
\leanok
\uses{def:vertex_partition}

The union of all $\Sigma(v)$ equals the set of all matter qudits:
\[
\bigcup_{v \in \mathcal{G}_0} \Sigma(v) = M.
\]
\end{theorem}

\begin{proof}
\leanok

This follows directly from the union property of the underlying indexed partition structure.
\end{proof}

\begin{theorem}[Existence of Membership]
\label{thm:exists_mem}
\lean{GaugingLDPC.VertexPartition.exists_mem}
\leanok
\uses{def:vertex_partition}

Every matter qudit $q$ belongs to some $\Sigma(v)$: for all $q \in M$, there exists $v \in \mathcal{G}_0$ such that $q \in \Sigma(v)$.
\end{theorem}

\begin{proof}
\leanok

This follows directly from the exists\_mem property of the underlying indexed partition.
\end{proof}

\begin{definition}[Index Function]
\label{def:index}
\lean{GaugingLDPC.VertexPartition.index}
\leanok
\uses{def:vertex_partition}

The \emph{index function} $\mathrm{index} : M \to \mathcal{G}_0$ assigns each qudit to its unique vertex, i.e., $\mathrm{index}(q) = v$ if and only if $q \in \Sigma(v)$.
\end{definition}

\begin{theorem}[Membership Characterization via Index]
\label{thm:mem_iff_index_eq}
\lean{GaugingLDPC.VertexPartition.mem_iff_index_eq}
\leanok
\uses{def:index}

A qudit $q$ belongs to $\Sigma(v)$ if and only if its index is $v$:
\[
q \in \Sigma(v) \iff \mathrm{index}(q) = v.
\]
\end{theorem}

\begin{proof}
\leanok

This follows directly from the mem\_iff\_index\_eq property of the underlying indexed partition.
\end{proof}

\begin{theorem}[Qudit Membership at Index]
\label{thm:mem_index}
\lean{GaugingLDPC.VertexPartition.mem_index}
\leanok
\uses{def:index}

Each qudit $q$ belongs to $\Sigma$ of its index: $q \in \Sigma(\mathrm{index}(q))$.
\end{theorem}

\begin{proof}
\leanok

This follows directly from the mem\_index property of the underlying indexed partition.
\end{proof}

\begin{theorem}[Uniqueness of Vertex]
\label{thm:eq_of_mem}
\lean{GaugingLDPC.VertexPartition.eq_of_mem}
\leanok
\uses{def:vertex_partition}

If a qudit $q$ is in both $\Sigma(v)$ and $\Sigma(w)$, then $v = w$.
\end{theorem}

\begin{proof}
\leanok

This follows directly from the eq\_of\_mem property of the underlying indexed partition.
\end{proof}

\begin{definition}[Parts]
\label{def:parts}
\lean{GaugingLDPC.VertexPartition.parts}
\leanok
\uses{def:vertex_partition}

The \emph{parts} of a vertex partition is the range of $\Sigma$ as a set of sets:
\[
\mathrm{parts} = \{\Sigma(v) : v \in \mathcal{G}_0\}.
\]
\end{definition}

\begin{theorem}[Setoid Partition Property]
\label{thm:is_partition_of_nonempty}
\lean{GaugingLDPC.VertexPartition.isPartition_of_nonempty}
\leanok
\uses{def:index, def:parts, thm:eq_of_mem, thm:mem_index}

If all $\Sigma(v)$ are nonempty, then the parts form a setoid partition in the Mathlib sense.
\end{theorem}

\begin{proof}
\leanok
\uses{thm:eq_of_mem, thm:mem_index}
We verify the two conditions for a setoid partition:

\textbf{Condition 1}: $\emptyset \notin \mathrm{parts}$. Suppose for contradiction that $\emptyset \in \mathrm{parts}$. Then there exists $v$ such that $\Sigma(v) = \emptyset$. This contradicts the hypothesis that all $\Sigma(v)$ are nonempty.

\textbf{Condition 2}: For all $q$, there exists a unique $s \in \mathrm{parts}$ such that $q \in s$. Let $q$ be arbitrary. We take $s = \Sigma(\mathrm{index}(q))$.
\begin{itemize}
    \item Existence: By definition, $\Sigma(\mathrm{index}(q)) \in \mathrm{parts}$ (witnessed by $\mathrm{index}(q)$), and by the mem\_index theorem, $q \in \Sigma(\mathrm{index}(q))$.
    \item Uniqueness: Let $s \in \mathrm{parts}$ with $q \in s$. Then there exists $w$ such that $s = \Sigma(w)$ and $q \in \Sigma(w)$. By the uniqueness theorem (eq\_of\_mem), since $q \in \Sigma(w)$ and $q \in \Sigma(\mathrm{index}(q))$, we have $w = \mathrm{index}(q)$, so $s = \Sigma(\mathrm{index}(q))$.
\end{itemize}
\end{proof}

\begin{definition}[Representative Qudit]
\label{def:some}
\lean{GaugingLDPC.VertexPartition.some}
\leanok
\uses{def:vertex_partition}

For each vertex $v$, the function $\mathrm{some}(v)$ returns a representative qudit in $\Sigma(v)$.
\end{definition}

\begin{lemma}[Representative Membership]
\label{lem:some_mem}
\lean{GaugingLDPC.VertexPartition.some_mem}
\leanok
\uses{def:some}

The representative qudit of $v$ is in $\Sigma(v)$: $\mathrm{some}(v) \in \Sigma(v)$.
\end{lemma}

\begin{proof}
\leanok

This follows directly from the some\_mem property of the underlying indexed partition.
\end{proof}

\begin{lemma}[Index of Representative]
\label{lem:index_some}
\lean{GaugingLDPC.VertexPartition.index_some}
\leanok
\uses{def:index, def:some}

The index of the representative qudit is the original vertex: $\mathrm{index}(\mathrm{some}(v)) = v$.
\end{lemma}

\begin{proof}
\leanok

This follows directly from the index\_some property of the underlying indexed partition.
\end{proof}

\begin{lemma}[Membership in Sigma]
\label{lem:mem_sigma_iff}
\lean{GaugingLDPC.VertexPartition.mem_Sigma_iff}
\leanok
\uses{def:index, thm:mem_iff_index_eq}

For any qudit $q$ and vertex $v$: $q \in \Sigma(v) \iff \mathrm{index}(q) = v$.
\end{lemma}

\begin{proof}
\leanok
\uses{thm:mem_iff_index_eq}
This is precisely the mem\_iff\_index\_eq characterization.
\end{proof}

\begin{theorem}[Index Equality for Same Membership]
\label{thm:index_eq_of_mem_same}
\lean{GaugingLDPC.VertexPartition.index_eq_of_mem_same}
\leanok
\uses{def:index, thm:mem_iff_index_eq}

Two qudits in the same $\Sigma(v)$ have the same index: if $q_1, q_2 \in \Sigma(v)$, then $\mathrm{index}(q_1) = \mathrm{index}(q_2)$.
\end{theorem}

\begin{proof}
\leanok
\uses{thm:mem_iff_index_eq}
By the membership characterization (mem\_iff\_index\_eq), $q_1 \in \Sigma(v)$ implies $\mathrm{index}(q_1) = v$, and $q_2 \in \Sigma(v)$ implies $\mathrm{index}(q_2) = v$. Therefore $\mathrm{index}(q_1) = v = \mathrm{index}(q_2)$.
\end{proof}

\begin{definition}[Induced Setoid]
\label{def:to_setoid}
\lean{GaugingLDPC.VertexPartition.toSetoid}
\leanok
\uses{def:vertex_partition}

The \emph{induced setoid} is the equivalence relation on matter qudits where $q_1 \sim q_2$ if and only if they belong to the same $\Sigma(v)$.
\end{definition}

\begin{theorem}[Setoid Equivalence Characterization]
\label{thm:to_setoid_equiv_iff}
\lean{GaugingLDPC.VertexPartition.toSetoid_equiv_iff}
\leanok
\uses{def:index, def:to_setoid}

Two qudits are equivalent under the induced setoid if and only if they have the same index:
\[
q_1 \sim q_2 \iff \mathrm{index}(q_1) = \mathrm{index}(q_2).
\]
\end{theorem}

\begin{proof}
\leanok

This holds by reflexivity, as the setoid equivalence is defined precisely in terms of equal indices.
\end{proof}

\begin{definition}[Equivalence with Quotient]
\label{def:equiv_quotient}
\lean{GaugingLDPC.VertexPartition.equivQuotient}
\leanok
\uses{def:vertex_partition}

The \emph{equivalence with quotient} provides a bijection between the vertex set $\mathcal{G}_0$ and the quotient of matter qudits by the induced setoid.
\end{definition}

\begin{definition}[Projection]
\label{def:proj}
\lean{GaugingLDPC.VertexPartition.proj}
\leanok
\uses{def:vertex_partition}

The \emph{projection} $\mathrm{proj} : M \to M/{\sim}$ maps each qudit to its equivalence class under the induced setoid.
\end{definition}

\begin{theorem}[Projection Equality for Same Membership]
\label{thm:proj_eq_of_mem_same}
\lean{GaugingLDPC.VertexPartition.proj_eq_of_mem_same}
\leanok
\uses{def:proj, thm:index_eq_of_mem_same}

Qudits in the same $\Sigma(v)$ project to the same class: if $q_1, q_2 \in \Sigma(v)$, then $\mathrm{proj}(q_1) = \mathrm{proj}(q_2)$.
\end{theorem}

\begin{proof}
\leanok
\uses{thm:index_eq_of_mem_same}
By simplification using the projection equality criterion, it suffices to show that $\mathrm{index}(q_1) = \mathrm{index}(q_2)$. This follows directly from the index\_eq\_of\_mem\_same theorem applied to $h_1$ and $h_2$.
\end{proof}

\begin{theorem}[Projection Fiber]
\label{thm:proj_fiber}
\lean{GaugingLDPC.VertexPartition.proj_fiber}
\leanok
\uses{def:equiv_quotient, def:index, def:proj, thm:mem_iff_index_eq}

The fiber of the projection over a vertex's class is exactly $\Sigma(v)$:
\[
\mathrm{proj}^{-1}(\{\mathrm{equivQuotient}(v)\}) = \Sigma(v).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{thm:mem_iff_index_eq}
By extensionality, it suffices to show equality for arbitrary $q$. After simplification, we prove both directions:

$(\Rightarrow)$ Assume $\mathrm{proj}(q) = \mathrm{equivQuotient}(v)$. By the membership characterization, it suffices to show $\mathrm{index}(q) = v$. We have that $\mathrm{equivQuotient}(\mathrm{index}(q)) = \mathrm{equivQuotient}(v)$ by the equivQuotient\_index\_apply property and our hypothesis. Since equivQuotient is injective, we conclude $\mathrm{index}(q) = v$.

$(\Leftarrow)$ Assume $q \in \Sigma(v)$. By the membership characterization, $\mathrm{index}(q) = v$. Rewriting using the equivQuotient\_index\_apply property and substituting $\mathrm{index}(q) = v$, we obtain $\mathrm{proj}(q) = \mathrm{equivQuotient}(v)$.
\end{proof}

\chapter{Chain Complex Notation}
\begin{remark}[Chain Complex Notation]
\label{rem:chain_complex_notation}
\lean{GaugingLDPC}
\leanok

Let $\mathcal{G}$ be a connected graph. The \emph{chain complex} of $\mathcal{G}$ with coefficients in a field $A$ (typically $A = \mathbb{F}_p$ for prime $p$) consists of:

\begin{enumerate}
    \item \textbf{Chain groups}: $C_1(\mathcal{G}, A)$ is the $A$-vector space with basis the edges of $\mathcal{G}$, and $C_0(\mathcal{G}, A)$ is the $A$-vector space with basis the vertices of $\mathcal{G}$.
    
    \item \textbf{Boundary map}: $\partial_1: C_1(\mathcal{G}, A) \to C_0(\mathcal{G}, A)$ is the linear map defined on basis elements by $\partial_1(e) = v_+ - v_-$ where $e$ is an edge with endpoints $v_+$ and $v_-$ (with fixed orientation).
    
    \item \textbf{Augmentation map}: $\varepsilon: C_0(\mathcal{G}, A) \to A$ is the linear map defined by $\varepsilon(v) = 1$ for all vertices $v$. For a general chain $c = \sum_i c_i v_i$, we have $\varepsilon(c) = \sum_i c_i$.
    
    \item \textbf{Augmented sequence}: $C_1(\mathcal{G}) \to C_0(\mathcal{G}) \to A \to 0$.
\end{enumerate}
\end{remark}

\begin{definition}[Oriented Graph]
\label{def:oriented_graph}
\lean{GaugingLDPC.OrientedGraph}
\leanok

An \emph{oriented graph} on vertex type $V$ and edge type $E$ is a structure consisting of:
\begin{itemize}
    \item A \emph{source} function $\mathrm{source}: E \to V$ assigning to each edge its source vertex.
    \item A \emph{target} function $\mathrm{target}: E \to V$ assigning to each edge its target vertex.
    \item The condition that for all edges $e$, $\mathrm{source}(e) \neq \mathrm{target}(e)$ (edges connect distinct vertices).
\end{itemize}
\end{definition}

\begin{definition}[Vertex Basis]
\label{def:vertex_basis}
\lean{GaugingLDPC.vertexBasis}
\leanok
\uses{def:oriented_graph}

For a vertex $v \in V$, the \emph{vertex basis element} is the element of $C_0(\mathcal{G}, A) = V \to_0 A$ defined by
\[
\mathbf{e}_v := \delta_v \in V \to_0 A,
\]
where $\delta_v$ is the Kronecker delta function sending $v$ to $1$ and all other vertices to $0$.
\end{definition}

\begin{definition}[Edge Basis]
\label{def:edge_basis}
\lean{GaugingLDPC.edgeBasis}
\leanok
\uses{def:oriented_graph}

For an edge $e \in E$, the \emph{edge basis element} is the element of $C_1(\mathcal{G}, A) = E \to_0 A$ defined by
\[
\mathbf{e}_e := \delta_e \in E \to_0 A,
\]
where $\delta_e$ is the Kronecker delta function sending $e$ to $1$ and all other edges to $0$.
\end{definition}

\begin{definition}[Boundary of Edge]
\label{def:boundary_of_edge}
\lean{GaugingLDPC.boundaryOfEdge}
\leanok
\uses{def:oriented_graph}

The \emph{boundary of a single edge} $e \in E$ is the $0$-chain defined by
\[
\partial_1(e) := \delta_{\mathrm{target}(e)} - \delta_{\mathrm{source}(e)} \in V \to_0 A,
\]
where $\delta_v$ denotes the basis element for vertex $v$.
\end{definition}

\begin{definition}[Boundary Map]
\label{def:boundary_map}
\lean{GaugingLDPC.boundaryMap}
\leanok
\uses{def:boundary_of_edge}

The \emph{boundary map} $\partial_1: C_1(\mathcal{G}, A) \to C_0(\mathcal{G}, A)$ is the $A$-linear map defined on basis elements by $\partial_1(e) = \mathrm{target}(e) - \mathrm{source}(e)$ and extended linearly. Formally, for a $1$-chain $c = \sum_e c_e \cdot e$,
\[
\partial_1(c) = \sum_e c_e \cdot \partial_1(e) = \sum_e c_e \cdot (\delta_{\mathrm{target}(e)} - \delta_{\mathrm{source}(e)}).
\]
\end{definition}

\begin{theorem}[Boundary Map on Single Edge]
\label{thm:boundary_map_single}
\lean{GaugingLDPC.boundaryMap_single}
\leanok
\uses{def:boundary_map, def:boundary_of_edge}

For any edge $e \in E$,
\[
\partial_1(\delta_e) = \partial_1(e),
\]
where $\delta_e$ is the basis element for edge $e$ in $C_1(\mathcal{G}, A)$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:boundary_map}

This follows directly by simplification using the definition of the boundary map.
\end{proof}

\begin{theorem}[Boundary of Edge Expanded Form]
\label{thm:boundary_of_edge_eq}
\lean{GaugingLDPC.boundaryOfEdge_eq}
\leanok
\uses{def:boundary_of_edge}

For any edge $e \in E$,
\[
\partial_1(e) = \delta_{\mathrm{target}(e)} - \delta_{\mathrm{source}(e)}.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:boundary_of_edge}

This holds by reflexivity (it is the definition).
\end{proof}

\begin{theorem}[Boundary Map at a Vertex]
\label{thm:boundary_map_apply_vertex}
\lean{GaugingLDPC.boundaryMap_apply_vertex}
\leanok
\uses{def:boundary_map, def:boundary_of_edge}

For a $1$-chain $c \in C_1(\mathcal{G}, A)$ and a vertex $v \in V$,
\[
(\partial_1(c))(v) = \sum_{e \in \mathrm{supp}(c)} c_e \cdot (\partial_1(e))(v).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:boundary_map, def:boundary_of_edge}

By the definition of the boundary map and the properties of finitely supported sums, we have
\[
(\partial_1(c))(v) = \left(\sum_e c_e \cdot \partial_1(e)\right)(v) = \sum_e c_e \cdot (\partial_1(e))(v).
\]
This follows by simplification using the linear combination definition and the application of finitely supported functions.
\end{proof}

\begin{definition}[Augmentation Map]
\label{def:augmentation_map}
\lean{GaugingLDPC.augmentationMap}
\leanok
\uses{def:oriented_graph}

The \emph{augmentation map} $\varepsilon: C_0(\mathcal{G}, A) \to A$ is the $A$-linear map that sends each vertex to $1$ and extends linearly. For a $0$-chain $c = \sum_i c_i v_i$,
\[
\varepsilon(c) = \sum_i c_i.
\]
\end{definition}

\begin{theorem}[Augmentation of Single Vertex]
\label{thm:augmentation_map_single}
\lean{GaugingLDPC.augmentationMap_single}
\leanok
\uses{def:augmentation_map}

For any vertex $v \in V$,
\[
\varepsilon(\delta_v) = 1.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:augmentation_map}

This follows directly by simplification using the definition of the augmentation map.
\end{proof}

\begin{theorem}[Augmentation as Sum of Coefficients]
\label{thm:augmentation_map_eq_sum}
\lean{GaugingLDPC.augmentationMap_eq_sum}
\leanok
\uses{def:augmentation_map}

For a $0$-chain $c \in C_0(\mathcal{G}, A)$,
\[
\varepsilon(c) = \sum_{v \in \mathrm{supp}(c)} c_v.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:augmentation_map}

By the definition of the augmentation map as a linear combination, we have
\[
\varepsilon(c) = \sum_{v \in \mathrm{supp}(c)} c_v \cdot 1 = \sum_{v \in \mathrm{supp}(c)} c_v.
\]
By extensionality, we verify that $c_v \cdot 1 = c_v$ using the property that multiplication by one is the identity.
\end{proof}

\begin{theorem}[Augmentation as Sum over All Vertices]
\label{thm:augmentation_map_eq_finsum}
\lean{GaugingLDPC.augmentationMap_eq_finsum}
\leanok
\uses{def:augmentation_map, thm:augmentation_map_eq_sum}

For a $0$-chain $c \in C_0(\mathcal{G}, A)$,
\[
\varepsilon(c) = \sum_{v \in V} c_v.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{thm:augmentation_map_eq_sum}

We rewrite using the formula $\varepsilon(c) = \sum_{v \in \mathrm{supp}(c)} c_v$. Since the support is a subset of the full vertex set $V$, we can extend the sum to all of $V$. For vertices $v \notin \mathrm{supp}(c)$, we have $c_v = 0$, so these terms contribute zero to the sum. Thus the equality holds.
\end{proof}

\begin{theorem}[Chain Complex Property]
\label{thm:augmentation_comp_boundary_eq_zero}
\lean{GaugingLDPC.augmentation_comp_boundary_eq_zero}
\leanok
\uses{def:augmentation_map, def:boundary_map, def:boundary_of_edge}

The composition of the augmentation map with the boundary map is zero:
\[
\varepsilon \circ \partial_1 = 0.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:augmentation_map, def:boundary_map, def:boundary_of_edge}

We apply linear map extensionality: it suffices to show that for any $1$-chain $c$, $\varepsilon(\partial_1(c)) = 0$.

Using the definition of the boundary map as a linear combination, we rewrite $\partial_1(c)$ as a sum over edges. Then applying the augmentation map and using the sum-of-sums index property, we obtain
\[
\varepsilon(\partial_1(c)) = \sum_{e \in \mathrm{supp}(c)} c_e \cdot \varepsilon(\partial_1(e)).
\]

For each edge $e$, we have $\partial_1(e) = \delta_{\mathrm{target}(e)} - \delta_{\mathrm{source}(e)}$. The scalar $c_e$ distributes over this difference. Using the subtraction index property for finitely supported sums, we get
\[
\varepsilon(c_e \cdot \partial_1(e)) = c_e \cdot \varepsilon(\delta_{\mathrm{target}(e)}) - c_e \cdot \varepsilon(\delta_{\mathrm{source}(e)}) = c_e \cdot 1 - c_e \cdot 1 = 0.
\]

Since each summand is zero, the entire sum equals zero.
\end{proof}

\begin{theorem}[Augmentation of Boundary is Zero]
\label{thm:augmentation_map_boundary_map}
\lean{GaugingLDPC.augmentationMap_boundaryMap}
\leanok
\uses{def:augmentation_map, def:boundary_map, thm:augmentation_comp_boundary_eq_zero}

For any $1$-chain $c \in C_1(\mathcal{G}, A)$,
\[
\varepsilon(\partial_1(c)) = 0.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{thm:augmentation_comp_boundary_eq_zero}

This follows directly from the chain complex property $\varepsilon \circ \partial_1 = 0$ by applying both sides to $c$.
\end{proof}

\begin{theorem}[Augmentation of Boundary of Edge is Zero]
\label{thm:augmentation_map_boundary_of_edge}
\lean{GaugingLDPC.augmentationMap_boundaryOfEdge}
\leanok
\uses{def:augmentation_map, def:boundary_of_edge, thm:augmentation_map_single}

For any edge $e \in E$,
\[
\varepsilon(\partial_1(e)) = 0.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:boundary_of_edge, thm:augmentation_map_single}

Using the definition of the boundary of an edge, we rewrite
\[
\varepsilon(\partial_1(e)) = \varepsilon(\delta_{\mathrm{target}(e)} - \delta_{\mathrm{source}(e)}) = \varepsilon(\delta_{\mathrm{target}(e)}) - \varepsilon(\delta_{\mathrm{source}(e)}) = 1 - 1 = 0.
\]
\end{proof}

\begin{theorem}[Boundary Map Preserves Zero]
\label{thm:boundary_map_zero}
\lean{GaugingLDPC.boundaryMap_zero}
\leanok
\uses{def:boundary_map}

$\partial_1(0) = 0$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:boundary_map}

This follows from the fact that $\partial_1$ is a linear map, which preserves zero.
\end{proof}

\begin{theorem}[Augmentation Map Preserves Zero]
\label{thm:augmentation_map_zero}
\lean{GaugingLDPC.augmentationMap_zero}
\leanok
\uses{def:augmentation_map}

$\varepsilon(0) = 0$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:augmentation_map}

This follows from the fact that $\varepsilon$ is a linear map, which preserves zero.
\end{proof}

\begin{theorem}[Boundary is Additive]
\label{thm:boundary_map_add}
\lean{GaugingLDPC.boundaryMap_add}
\leanok
\uses{def:boundary_map}

For any $1$-chains $c_1, c_2 \in C_1(\mathcal{G}, A)$,
\[
\partial_1(c_1 + c_2) = \partial_1(c_1) + \partial_1(c_2).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:boundary_map}

This follows from the additivity property of linear maps.
\end{proof}

\begin{theorem}[Augmentation is Additive]
\label{thm:augmentation_map_add}
\lean{GaugingLDPC.augmentationMap_add}
\leanok
\uses{def:augmentation_map}

For any $0$-chains $c_1, c_2 \in C_0(\mathcal{G}, A)$,
\[
\varepsilon(c_1 + c_2) = \varepsilon(c_1) + \varepsilon(c_2).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:augmentation_map}

This follows from the additivity property of linear maps.
\end{proof}

\begin{theorem}[Boundary Respects Scalar Multiplication]
\label{thm:boundary_map_smul}
\lean{GaugingLDPC.boundaryMap_smul}
\leanok
\uses{def:boundary_map}

For any $a \in A$ and $1$-chain $c \in C_1(\mathcal{G}, A)$,
\[
\partial_1(a \cdot c) = a \cdot \partial_1(c).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:boundary_map}

This follows from the scalar multiplication property of linear maps.
\end{proof}

\begin{theorem}[Augmentation Respects Scalar Multiplication]
\label{thm:augmentation_map_smul}
\lean{GaugingLDPC.augmentationMap_smul}
\leanok
\uses{def:augmentation_map}

For any $a \in A$ and $0$-chain $c \in C_0(\mathcal{G}, A)$,
\[
\varepsilon(a \cdot c) = a \cdot \varepsilon(c).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:augmentation_map}

This follows from the scalar multiplication property of linear maps.
\end{proof}

\begin{theorem}[Range of Boundary Contained in Kernel of Augmentation]
\label{thm:range_boundary_le_ker_augmentation}
\lean{GaugingLDPC.range_boundary_le_ker_augmentation}
\leanok
\uses{def:augmentation_map, def:boundary_map, thm:augmentation_map_boundary_map}

The image of the boundary map is contained in the kernel of the augmentation map:
\[
\mathrm{im}(\partial_1) \subseteq \ker(\varepsilon).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{thm:augmentation_map_boundary_map}

Let $x \in \mathrm{im}(\partial_1)$. Then there exists a $1$-chain $c$ such that $x = \partial_1(c)$. By the theorem that $\varepsilon(\partial_1(c)) = 0$, we have $\varepsilon(x) = 0$, so $x \in \ker(\varepsilon)$.
\end{proof}

\begin{theorem}[Boundary Elements are in Kernel of Augmentation]
\label{thm:mem_ker_augmentation_of_boundary}
\lean{GaugingLDPC.mem_ker_augmentation_of_boundary}
\leanok
\uses{def:augmentation_map, def:boundary_map, thm:augmentation_map_boundary_map}

For any $1$-chain $c \in C_1(\mathcal{G}, A)$,
\[
\partial_1(c) \in \ker(\varepsilon).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{thm:augmentation_map_boundary_map}

By definition of kernel membership, we need $\varepsilon(\partial_1(c)) = 0$, which follows directly from the theorem that augmentation of boundary is zero.
\end{proof}

\begin{theorem}[Augmentation Map is Surjective]
\label{thm:augmentation_map_surjective}
\lean{GaugingLDPC.augmentationMap_surjective}
\leanok
\uses{def:augmentation_map, thm:augmentation_map_single}

Assuming the graph has at least one vertex, the augmentation map $\varepsilon: C_0(\mathcal{G}, A) \to A$ is surjective.
\end{theorem}

\begin{proof}
\leanok
\uses{thm:augmentation_map_single}

Let $a \in A$ be arbitrary. Since $V$ is nonempty, we can obtain a vertex $v \in V$. Consider the $0$-chain $a \cdot \delta_v$. Then
\[
\varepsilon(a \cdot \delta_v) = a \cdot \varepsilon(\delta_v) = a \cdot 1 = a.
\]
Thus $a$ is in the image of $\varepsilon$, and since $a$ was arbitrary, $\varepsilon$ is surjective.
\end{proof}

\begin{theorem}[Vertex Basis Elements Span $C_0$]
\label{thm:span_vertex_basis}
\lean{GaugingLDPC.span_vertexBasis}
\leanok
\uses{def:vertex_basis}

The set of vertex basis elements $\{\delta_v : v \in V\}$ spans $C_0(\mathcal{G}, A)$:
\[
\mathrm{span}_A\{\delta_v : v \in V\} = C_0(\mathcal{G}, A).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:vertex_basis}

We show that every element of $C_0(\mathcal{G}, A)$ is in the span. Let $c \in C_0(\mathcal{G}, A)$ be arbitrary. We show that $c$ lies in every submodule $p$ that contains the range of the vertex basis function.

First, we establish that $c = \sum_{v \in \mathrm{supp}(c)} c_v \cdot \delta_v$. By extensionality, for any vertex $v$, the $v$-component of the right-hand side equals $c_v$: using the single-out property of finitely supported sums, only the term for $v$ contributes, giving $c_v \cdot 1 = c_v$. Terms for other vertices $b \neq v$ contribute zero, and if $v \notin \mathrm{supp}(c)$, then $c_v = 0$.

Now, since $c$ is a finite sum of scalar multiples of vertex basis elements, and submodules are closed under finite sums and scalar multiplication, we have $c \in p$ for any submodule $p$ containing the basis elements. Thus $c$ is in the span.
\end{proof}

\begin{theorem}[Edge Basis Elements Span $C_1$]
\label{thm:span_edge_basis}
\lean{GaugingLDPC.span_edgeBasis}
\leanok
\uses{def:edge_basis}

The set of edge basis elements $\{\delta_e : e \in E\}$ spans $C_1(\mathcal{G}, A)$:
\[
\mathrm{span}_A\{\delta_e : e \in E\} = C_1(\mathcal{G}, A).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:edge_basis}

We show that every element of $C_1(\mathcal{G}, A)$ is in the span. Let $c \in C_1(\mathcal{G}, A)$ be arbitrary. We show that $c$ lies in every submodule $p$ that contains the range of the edge basis function.

First, we establish that $c = \sum_{e \in \mathrm{supp}(c)} c_e \cdot \delta_e$. By extensionality, for any edge $e$, the $e$-component of the right-hand side equals $c_e$: using the single-out property of finitely supported sums, only the term for $e$ contributes, giving $c_e \cdot 1 = c_e$. Terms for other edges $b \neq e$ contribute zero, and if $e \notin \mathrm{supp}(c)$, then $c_e = 0$.

Now, since $c$ is a finite sum of scalar multiples of edge basis elements, and submodules are closed under finite sums and scalar multiplication, we have $c \in p$ for any submodule $p$ containing the basis elements. Thus $c$ is in the span.
\end{proof}

\chapter{Symmetry Action and Abelian Group Structure}
\begin{remark}[Symmetry Action and Abelian Group Structure]
\label{rem:symmetry_action_and_abelian_group_structure}
\lean{GaugingLDPC}
\leanok

Let $A = \mathbb{Z}_p$ be a cyclic group of prime order $p$ acting as an on-site symmetry on the Hilbert space of a quantum code. The symmetry action is described by:

\begin{enumerate}
\item \textbf{Automorphism}: For each $g \in A$, there is an automorphism $\varphi_g$ of the operator algebra acting on the code's Hilbert space.

\item \textbf{On-site symmetry operator}: $\mathsf{T}$ denotes the generator of the symmetry, satisfying $\mathsf{T}^p = \mathbf{1}$ (identity). For a subset $\Sigma(v)$ of qudits, $\mathsf{T}|_{\Sigma(v)}$ denotes the restriction of $\mathsf{T}$ to act only on qudits in $\Sigma(v)$.

\item \textbf{Character group}: $\hat{A} = \{\chi: A \to \mathbb{C}^* \mid \chi(g_1 g_2) = \chi(g_1)\chi(g_2)\}$ is the group of characters. For $A = \mathbb{Z}_p$, characters are $\chi_k(g) = e^{2\pi i k g / p}$ for $k = 0, 1, \ldots, p-1$.
\end{enumerate}
\end{remark}

\begin{definition}[Symmetry Group]
\label{def:symmetry_group}
\lean{GaugingLDPC.SymmetryGroup}
\leanok

The \emph{symmetry group} $A = \mathbb{Z}_p$ is the cyclic group of prime order $p$, modeled as the additive group $\mathbb{Z}/p\mathbb{Z}$.
\end{definition}

\begin{theorem}[Symmetry Group is Cyclic]
\label{thm:is_add_cyclic}
\lean{GaugingLDPC.SymmetryGroup.isAddCyclic}
\leanok
\uses{def:symmetry_group}

The symmetry group $\mathbb{Z}_p$ is a cyclic group (under addition).
\end{theorem}

\begin{proof}
\leanok
\uses{def:symmetry_group}
This follows directly from the fact that $\mathbb{Z}/p\mathbb{Z}$ is cyclic, which is a standard result in Mathlib.
\end{proof}

\begin{theorem}[Cardinality of Symmetry Group]
\label{thm:card_eq_p}
\lean{GaugingLDPC.SymmetryGroup.card_eq_p}
\leanok
\uses{def:symmetry_group}

The order of the symmetry group $\mathbb{Z}_p$ is $p$, i.e., $|A| = p$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:symmetry_group}
This holds by the definition of $\mathbb{Z}/p\mathbb{Z}$, which has exactly $p$ elements.
\end{proof}

\begin{lemma}[Group Operation]
\label{lem:add_def}
\lean{GaugingLDPC.SymmetryGroup.add_def}
\leanok
\uses{def:symmetry_group}

For $a, b \in \mathbb{Z}_p$, the group operation is given by $a + b = (a + b) \mod p$.
\end{lemma}

\begin{proof}
\leanok
\uses{def:symmetry_group}
This holds by reflexivity, as this is the definition of addition in $\mathbb{Z}/p\mathbb{Z}$.
\end{proof}

\begin{lemma}[Zero is Identity]
\label{lem:zero_eq_identity}
\lean{GaugingLDPC.SymmetryGroup.zero_eq_identity}
\leanok
\uses{def:symmetry_group}

The element $0 \in \mathbb{Z}_p$ is the identity element of the group.
\end{lemma}

\begin{proof}
\leanok
\uses{def:symmetry_group}
This holds by reflexivity.
\end{proof}

\begin{theorem}[Generator Generates]
\label{thm:generator_generates}
\lean{GaugingLDPC.SymmetryGroup.generator_generates}
\leanok
\uses{def:symmetry_group}

The element $1 \in \mathbb{Z}_p$ generates the entire group: for every $g \in \mathbb{Z}_p$, there exists $n \in \mathbb{N}$ such that $g = n \cdot 1$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:symmetry_group}
Let $g \in \mathbb{Z}_p$ be arbitrary. We take $n = g.\mathrm{val}$ (the natural number representative of $g$). Using the fact that $n \cdot 1 = n$ and the property that casting $g.\mathrm{val}$ back to $\mathbb{Z}_p$ gives $g$, we obtain $g = n \cdot 1$.
\end{proof}

\begin{theorem}[Additive Order Divides $p$]
\label{thm:add_order_of_dvd_p}
\lean{GaugingLDPC.SymmetryGroup.addOrderOf_dvd_p}
\leanok
\uses{def:symmetry_group, thm:card_eq_p}

For any element $g \in \mathbb{Z}_p$, the additive order of $g$ divides $p$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:symmetry_group, thm:card_eq_p}
By Lagrange's theorem, the order of any element divides the order of the group. Since $|\mathbb{Z}_p| = p$ by the cardinality theorem, the additive order of $g$ divides $p$.
\end{proof}

\begin{definition}[Operator Algebra]
\label{def:operator_algebra}
\lean{GaugingLDPC.OperatorAlgebra}
\leanok

An \emph{operator algebra} over $\mathbb{C}$ is a ring $R$ equipped with a $\mathbb{C}$-algebra structure. This serves as a placeholder for the algebra of operators acting on a quantum code's Hilbert space.
\end{definition}

\begin{definition}[Operator Algebra Automorphism]
\label{def:operator_algebra_aut}
\lean{GaugingLDPC.OperatorAlgebraAut}
\leanok

The type of \emph{automorphisms} of an operator algebra $R$ is the group of ring automorphisms $\mathrm{Aut}(R)$. For each $g \in A$, $\varphi_g$ is an automorphism of $R$.
\end{definition}

\begin{definition}[Symmetry Action]
\label{def:symmetry_action}
\lean{GaugingLDPC.SymmetryAction}
\leanok
\uses{def:operator_algebra_aut, def:symmetry_group, thm:map_zero}

A \emph{symmetry action} of the group $A = \mathbb{Z}_p$ on an operator algebra $R$ via automorphisms consists of:
\begin{itemize}
\item A map $\varphi: A \to \mathrm{Aut}(R)$ associating to each group element $g$ an automorphism $\varphi_g$,
\item The homomorphism property: $\varphi(g_1 + g_2) = \varphi(g_1) \circ \varphi(g_2)$,
\item The identity property: $\varphi(0) = \mathrm{id}$.
\end{itemize}
\end{definition}

\begin{definition}[Automorphism Map]
\label{def:automorphism}
\lean{GaugingLDPC.SymmetryAction.automorphism}
\leanok
\uses{def:operator_algebra_aut, def:symmetry_group}

For a symmetry action $\sigma$ and group element $g \in A$, the \emph{automorphism} $\sigma.\mathrm{automorphism}(g) = \varphi_g$ is the ring automorphism associated to $g$.
\end{definition}

\begin{theorem}[Automorphism at Zero]
\label{thm:automorphism_zero}
\lean{GaugingLDPC.SymmetryAction.automorphism_zero}
\leanok
\uses{def:automorphism, thm:map_zero}

For any symmetry action $\sigma$, the automorphism at the identity element is the identity: $\varphi_0 = \mathrm{id}$.
\end{theorem}

\begin{proof}
\leanok
\uses{thm:map_zero}
This follows directly from the $\mathrm{map\_zero}$ property of the symmetry action structure.
\end{proof}

\begin{theorem}[Automorphism Addition]
\label{thm:automorphism_add}
\lean{GaugingLDPC.SymmetryAction.automorphism_add}
\leanok
\uses{def:automorphism, def:symmetry_group}

For any symmetry action $\sigma$ and elements $g_1, g_2 \in A$:
\[
\varphi_{g_1 + g_2} = \varphi_{g_1} \circ \varphi_{g_2}
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:automorphism, def:symmetry_group}
This follows directly from the $\mathrm{map\_add}$ property of the symmetry action structure.
\end{proof}

\begin{definition}[Monoid Homomorphism]
\label{def:to_monoid_hom}
\lean{GaugingLDPC.SymmetryAction.toMonoidHom}
\leanok
\uses{def:operator_algebra_aut, def:symmetry_group, thm:map_zero}

The symmetry action can be viewed as a monoid homomorphism from the multiplicative version of $A$ to $\mathrm{Aut}(R)$:
\[
\mathrm{toMonoidHom}: \mathrm{Multiplicative}(A) \to \mathrm{Aut}(R)
\]
where $\mathrm{toMonoidHom}(g) = \varphi_g$.
\end{definition}

\begin{definition}[On-site Symmetry Operator]
\label{def:onsite_symmetry_op}
\lean{GaugingLDPC.OnsiteSymmetryOp}
\leanok
\uses{def:symmetry_group}

An \emph{on-site symmetry operator} $\mathsf{T}$ is a unitary operator in an operator algebra $R$ satisfying:
\begin{itemize}
\item $\mathsf{T}$ is invertible (i.e., $\mathsf{T}$ is a unit in $R$),
\item $\mathsf{T}^p = 1$ (the identity).
\end{itemize}
This represents the generator of the $\mathbb{Z}_p$ symmetry action.
\end{definition}

\begin{definition}[Powers of Symmetry Operator]
\label{def:powers}
\lean{GaugingLDPC.OnsiteSymmetryOp.powers}
\leanok
\uses{def:onsite_symmetry_op}

For an on-site symmetry operator $\mathsf{T}$ and $k \in \mathbb{Z}_p$, the \emph{power} $\mathsf{T}^k$ is defined as $\mathsf{T}^{k.\mathrm{val}}$ where $k.\mathrm{val} \in \{0, 1, \ldots, p-1\}$ is the natural number representative of $k$.
\end{definition}

\begin{theorem}[Powers at Zero]
\label{thm:powers_zero}
\lean{GaugingLDPC.OnsiteSymmetryOp.powers_zero}
\leanok
\uses{def:powers}

For any on-site symmetry operator $\mathsf{T}$: $\mathsf{T}^0 = 1$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:powers}
By simplification using the definition of powers, $\mathsf{T}^{0.\mathrm{val}} = \mathsf{T}^0 = 1$.
\end{proof}

\begin{theorem}[Powers Addition]
\label{thm:powers_add}
\lean{GaugingLDPC.OnsiteSymmetryOp.powers_add}
\leanok
\uses{def:powers}

For any on-site symmetry operator $\mathsf{T}$ and $k_1, k_2 \in \mathbb{Z}_p$:
\[
\mathsf{T}^{k_1 + k_2} = \mathsf{T}^{k_1} \cdot \mathsf{T}^{k_2} \quad \text{or} \quad \mathsf{T}^{k_1 + k_2} \cdot \mathsf{T}^p = \mathsf{T}^{k_1} \cdot \mathsf{T}^{k_2}
\]
(The first equality holds when $k_1.\mathrm{val} + k_2.\mathrm{val} < p$; otherwise the second holds, but since $\mathsf{T}^p = 1$, both cases give $\mathsf{T}^{k_1 + k_2} = \mathsf{T}^{k_1} \cdot \mathsf{T}^{k_2}$.)
\end{theorem}

\begin{proof}
\leanok
\uses{def:powers}
We prove the first case. By simplification using the definition of powers, we consider two cases based on whether $k_1.\mathrm{val} + k_2.\mathrm{val} < p$.

\textbf{Case 1:} If $k_1.\mathrm{val} + k_2.\mathrm{val} < p$, then $(k_1 + k_2).\mathrm{val} = k_1.\mathrm{val} + k_2.\mathrm{val}$, and the result follows from $\mathsf{T}^{a+b} = \mathsf{T}^a \cdot \mathsf{T}^b$.

\textbf{Case 2:} If $k_1.\mathrm{val} + k_2.\mathrm{val} \geq p$, then $(k_1 + k_2).\mathrm{val} = k_1.\mathrm{val} + k_2.\mathrm{val} - p$. We compute:
\begin{align*}
\mathsf{T}^{(k_1 + k_2).\mathrm{val}} &= \mathsf{T}^{k_1.\mathrm{val} + k_2.\mathrm{val} - p} \\
&= \mathsf{T}^{k_1.\mathrm{val} + k_2.\mathrm{val} - p} \cdot 1 \\
&= \mathsf{T}^{k_1.\mathrm{val} + k_2.\mathrm{val} - p} \cdot \mathsf{T}^p \\
&= \mathsf{T}^{k_1.\mathrm{val} + k_2.\mathrm{val}} \\
&= \mathsf{T}^{k_1.\mathrm{val}} \cdot \mathsf{T}^{k_2.\mathrm{val}}
\end{align*}
\end{proof}

\begin{definition}[Primitive Root of Unity]
\label{def:primitive_root}
\lean{GaugingLDPC.CharacterGroup.primitiveRoot}
\leanok

The \emph{primitive $p$-th root of unity} is $\zeta = e^{2\pi i/p} \in \mathbb{C}$.
\end{definition}

\begin{theorem}[Primitive Root Power]
\label{thm:primitive_root_pow_eq_one}
\lean{GaugingLDPC.CharacterGroup.primitiveRoot_pow_eq_one}
\leanok
\uses{def:primitive_root}

For $p \neq 0$ (as a complex number), $\zeta^p = 1$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:primitive_root}
By the definition of the primitive root, $\zeta = e^{2\pi i/p}$. Using the exponential law:
\[
\zeta^p = e^{p \cdot 2\pi i/p} = e^{2\pi i} = 1
\]
where the last equality follows from Euler's formula.
\end{proof}

\begin{definition}[Character Group]
\label{def:character_group}
\lean{GaugingLDPC.CharacterGroup}
\leanok

The \emph{character group} $\hat{A}$ of $A = \mathbb{Z}_p$ is the group of additive characters $\chi: \mathbb{Z}_p \to \mathbb{C}^*$, i.e., group homomorphisms from the additive group $\mathbb{Z}_p$ to the multiplicative group $\mathbb{C}^*$:
\[
\hat{A} = \mathrm{AddChar}(\mathbb{Z}_p, \mathbb{C})
\]
\end{definition}

\begin{theorem}[Character Multiplicativity]
\label{thm:mul_property}
\lean{GaugingLDPC.CharacterGroup.mul_property}
\leanok
\uses{def:character_group}

Characters are multiplicative: for any $\chi \in \hat{A}$ and $g_1, g_2 \in A$:
\[
\chi(g_1 + g_2) = \chi(g_1) \cdot \chi(g_2)
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:character_group}
This is the defining property of an additive character, given by $\mathrm{AddChar.map\_add\_eq\_mul}$.
\end{proof}

\begin{theorem}[Character at Zero]
\label{thm:map_zero}
\lean{GaugingLDPC.CharacterGroup.map_zero}
\leanok
\uses{def:character_group}

For any character $\chi \in \hat{A}$: $\chi(0) = 1$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:character_group}
This follows from $\mathrm{AddChar.map\_zero\_eq\_one}$, which states that additive characters map the additive identity to the multiplicative identity.
\end{proof}

\begin{theorem}[Character of Negation]
\label{thm:map_neg_eq_inv}
\lean{GaugingLDPC.CharacterGroup.map_neg_eq_inv}
\leanok
\uses{def:character_group, thm:map_zero, thm:mul_property}

For any character $\chi \in \hat{A}$ and $g \in A$:
\[
\chi(-g) = \chi(g)^{-1}
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:character_group, thm:map_zero, thm:mul_property}
We first establish that $\chi(g) \cdot \chi(-g) = 1$. By the multiplicativity property:
\[
\chi(g) \cdot \chi(-g) = \chi(g + (-g)) = \chi(0) = 1
\]
By commutativity, $\chi(-g) \cdot \chi(g) = 1$ as well. Therefore $\chi(-g) = \chi(g)^{-1}$ by the characterization of inverses.
\end{proof}

\begin{definition}[Standard Character]
\label{def:standard_char}
\lean{GaugingLDPC.CharacterGroup.standardChar}
\leanok
\uses{def:character_group}

The \emph{standard character} $\chi_k: \mathbb{Z}_p \to \mathbb{C}$ for $k \in \mathbb{Z}_p$ is defined by:
\[
\chi_k(g) = \exp\left(\frac{2\pi i \cdot k \cdot g}{p}\right)
\]
where $k$ and $g$ are interpreted as their natural number representatives in $\{0, 1, \ldots, p-1\}$.
\end{definition}

\begin{theorem}[Standard Character Formula]
\label{thm:standard_char_apply}
\lean{GaugingLDPC.CharacterGroup.standardChar_apply}
\leanok
\uses{def:standard_char}

For $k, g \in \mathbb{Z}_p$:
\[
\chi_k(g) = \exp\left(\frac{2\pi i \cdot k.\mathrm{val} \cdot g.\mathrm{val}}{p}\right)
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:standard_char}
This holds by reflexivity, as it is the definition of the standard character.
\end{proof}

\begin{theorem}[Trivial Character]
\label{thm:standard_char_zero}
\lean{GaugingLDPC.CharacterGroup.standardChar_zero}
\leanok
\uses{def:standard_char, thm:standard_char_apply}

The character $\chi_0$ is trivial: $\chi_0(g) = 1$ for all $g \in A$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:standard_char, thm:standard_char_apply}
By simplification using the standard character formula with $k = 0$:
\[
\chi_0(g) = \exp\left(\frac{2\pi i \cdot 0 \cdot g}{p}\right) = \exp(0) = 1
\]
\end{proof}

\begin{theorem}[Standard Character at Zero]
\label{thm:standard_char_at_zero}
\lean{GaugingLDPC.CharacterGroup.standardChar_at_zero}
\leanok
\uses{def:standard_char, thm:standard_char_apply}

For any $k \in \mathbb{Z}_p$: $\chi_k(0) = 1$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:standard_char, thm:standard_char_apply}
By simplification using the standard character formula with $g = 0$:
\[
\chi_k(0) = \exp\left(\frac{2\pi i \cdot k \cdot 0}{p}\right) = \exp(0) = 1
\]
\end{proof}

\begin{theorem}[Standard Character Multiplicativity]
\label{thm:standard_char_mul}
\lean{GaugingLDPC.CharacterGroup.standardChar_mul}
\leanok
\uses{def:standard_char, thm:mul_property}

Standard characters are multiplicative: for $k, g_1, g_2 \in \mathbb{Z}_p$:
\[
\chi_k(g_1 + g_2) = \chi_k(g_1) \cdot \chi_k(g_2)
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:standard_char, thm:mul_property}
This follows from the general multiplicativity theorem for characters applied to the standard character $\chi_k$.
\end{proof}

\begin{theorem}[Standard Character at One]
\label{thm:standard_char_at_one}
\lean{GaugingLDPC.CharacterGroup.standardChar_at_one}
\leanok
\uses{def:standard_char, thm:standard_char_apply}

For any $k \in \mathbb{Z}_p$:
\[
\chi_k(1) = \exp\left(\frac{2\pi i \cdot k}{p}\right)
\]
which is the $k$-th power of the primitive $p$-th root of unity.
\end{theorem}

\begin{proof}
\leanok
\uses{def:standard_char, thm:standard_char_apply}
By simplification using the standard character formula with $g = 1$ (noting that $1.\mathrm{val} = 1$):
\[
\chi_k(1) = \exp\left(\frac{2\pi i \cdot k.\mathrm{val} \cdot 1}{p}\right) = \exp\left(\frac{2\pi i \cdot k.\mathrm{val}}{p}\right)
\]
By ring arithmetic, this equals $\exp(2\pi i \cdot k.\mathrm{val} / p)$.
\end{proof}

\begin{theorem}[Character Group Cardinality]
\label{thm:character_group_card_eq_p}
\lean{GaugingLDPC.CharacterGroup.card_eq_p}
\leanok
\uses{def:character_group}

The character group $\hat{A}$ has order $p$: $|\hat{A}| = p$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:character_group}
Since $p \neq 0$, we apply the Mathlib result $\mathrm{AddChar.card\_eq}$ for the character group of $\mathbb{Z}/p\mathbb{Z}$, which states that $|\mathrm{AddChar}(\mathbb{Z}_p, \mathbb{C})| = |\mathbb{Z}_p| = p$.
\end{proof}

\begin{theorem}[Characters Take Values in Roots of Unity]
\label{thm:val_mem_roots_of_unity}
\lean{GaugingLDPC.CharacterGroup.val_mem_rootsOfUnity}
\leanok
\uses{def:character_group}

For any character $\chi \in \hat{A}$ and $g \in A$: $(\chi(g))^p = 1$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:character_group}
We show that $\chi(p \cdot g) = 1$. Since $p \cdot g = 0$ in $\mathbb{Z}_p$ (as $p \equiv 0 \pmod{p}$), we have $\chi(p \cdot g) = \chi(0) = 1$.

By the property that additive characters map scalar multiples to powers (i.e., $\chi(n \cdot g) = (\chi(g))^n$), we obtain $(\chi(g))^p = 1$.
\end{proof}

\begin{theorem}[Standard Characters Span]
\label{thm:standard_char_spans}
\lean{GaugingLDPC.CharacterGroup.standardChar_spans}
\leanok
\uses{def:character_group, def:standard_char, thm:standard_char_apply}

The standard characters $\chi_0, \chi_1, \ldots, \chi_{p-1}$ form the entire character group: for every $\chi \in \hat{A}$, there exists $k \in \mathbb{Z}_p$ such that $\chi = \chi_k$.
\end{theorem}

\begin{proof}
\leanok
\uses{def:character_group, def:standard_char, thm:standard_char_apply}
Let $\chi \in \hat{A}$ be arbitrary. Since $p \neq 0$, we can use the Mathlib equivalence $\mathrm{AddChar.zmodAddEquiv}: \mathbb{Z}_p \simeq \mathrm{AddChar}(\mathbb{Z}_p, \mathbb{C})$. By surjectivity, there exists $k \in \mathbb{Z}_p$ such that $\chi = \mathrm{AddChar.zmodAddEquiv}(k)$.

We show that $\chi_k = \mathrm{AddChar.zmodAddEquiv}(k)$. By extensionality, for any $g \in \mathbb{Z}_p$:
\begin{align*}
(\mathrm{AddChar.zmodAddEquiv}(k))(g) &= \mathrm{Circle.exp}\left(2\pi \cdot \frac{k \cdot g}{p}\right) \\
&= \exp\left(\frac{2\pi i \cdot k.\mathrm{val} \cdot g.\mathrm{val}}{p}\right) = \chi_k(g)
\end{align*}
The calculation uses the Mathlib definition of the circle character and the coercion from $\mathrm{Circle}$ to $\mathbb{C}$.
\end{proof}

\begin{definition}[Duality Pairing]
\label{def:duality_pairing}
\lean{GaugingLDPC.dualityPairing}
\leanok
\uses{def:character_group}

The \emph{duality pairing} between $A$ and $\hat{A}$ is defined for $g \in A$ and $\chi \in \hat{A}$ by:
\[
\langle g, \chi \rangle = \chi(g) \in \mathbb{C}^*
\]
\end{definition}

\begin{theorem}[Duality Pairing Additivity]
\label{thm:duality_pairing_add_left}
\lean{GaugingLDPC.dualityPairing_add_left}
\leanok
\uses{def:character_group, def:duality_pairing, thm:mul_property}

The duality pairing is multiplicative in the first argument: for $g_1, g_2 \in A$ and $\chi \in \hat{A}$:
\[
\langle g_1 + g_2, \chi \rangle = \langle g_1, \chi \rangle \cdot \langle g_2, \chi \rangle
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:duality_pairing, thm:mul_property}
This follows directly from the multiplicativity property of characters:
\[
\langle g_1 + g_2, \chi \rangle = \chi(g_1 + g_2) = \chi(g_1) \cdot \chi(g_2) = \langle g_1, \chi \rangle \cdot \langle g_2, \chi \rangle
\]
\end{proof}

\begin{theorem}[Duality Pairing with Standard Character]
\label{thm:duality_pairing_standard_char}
\lean{GaugingLDPC.dualityPairing_standardChar}
\leanok
\uses{def:character_group, def:duality_pairing, def:standard_char, thm:standard_char_apply}

For $g, k \in \mathbb{Z}_p$:
\[
\langle g, \chi_k \rangle = \exp\left(\frac{2\pi i \cdot k.\mathrm{val} \cdot g.\mathrm{val}}{p}\right)
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:duality_pairing, def:standard_char, thm:standard_char_apply}
This follows directly from the standard character formula.
\end{proof}

\begin{definition}[Symmetry Eigenvalue]
\label{def:symmetry_eigenvalue}
\lean{GaugingLDPC.symmetryEigenvalue}
\leanok
\uses{def:character_group, def:standard_char}

Given an on-site symmetry $\mathsf{T}$ and a character $\chi_k$, the \emph{eigenvalue of $\mathsf{T}$ under $\chi_k$} for a state in the $g$-sector is:
\[
\lambda_{k,g} = \chi_k(g) = \exp\left(\frac{2\pi i \cdot k \cdot g}{p}\right)
\]
This represents the eigenvalue when $\mathsf{T}$ acts as $e^{2\pi ig/p}$ on a state.
\end{definition}

\begin{theorem}[Trivial Eigenvalue]
\label{thm:symmetry_eigenvalue_trivial}
\lean{GaugingLDPC.symmetryEigenvalue_trivial}
\leanok
\uses{def:character_group, def:symmetry_eigenvalue, thm:standard_char_zero}

The eigenvalue for the trivial character is always $1$: for all $g \in A$:
\[
\lambda_{0,g} = 1
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:symmetry_eigenvalue, thm:standard_char_zero}
This follows from the fact that $\chi_0$ is the trivial character: $\lambda_{0,g} = \chi_0(g) = 1$.
\end{proof}

\begin{theorem}[Identity Eigenvalue]
\label{thm:symmetry_eigenvalue_identity}
\lean{GaugingLDPC.symmetryEigenvalue_identity}
\leanok
\uses{def:character_group, def:symmetry_eigenvalue, thm:standard_char_at_zero}

The eigenvalue at the identity element is always $1$: for all $k \in \mathbb{Z}_p$:
\[
\lambda_{k,0} = 1
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:symmetry_eigenvalue, thm:standard_char_at_zero}
This follows from the fact that all characters map $0$ to $1$: $\lambda_{k,0} = \chi_k(0) = 1$.
\end{proof}

\chapter{Charge Projection (Single Site)}
\section{Charge Projection (Single Site)}

Let $A = \mathbb{Z}_p$ be an Abelian symmetry group acting via automorphisms $\varphi_g$ on the operator algebra of a local Hilbert space. Let $\hat{A}$ denote the character group of $A$. For any operator $O$ and character $\chi \in \hat{A}$, we define the \textbf{charge-$\chi$ component} (or charge projection) of $O$.

\begin{definition}[Character Conjugate Value]
\label{def:char_conj_value}
\lean{GaugingLDPC.charConjValue}
\leanok
\uses{rem:symmetry_action_and_abelian_group_structure}

The \textbf{complex conjugate of a character value} $\chi(g)$ is defined as
\[
\overline{\chi(g)} := \mathrm{conj}(\chi(g)).
\]
For unitary characters (with values on the unit circle), we have $\overline{\chi(g)} = \chi(g)^{-1} = \chi(-g)$.
\end{definition}

\begin{theorem}[Conjugate of $\chi(0)$ is 1]
\label{thm:char_conj_value_zero}
\lean{GaugingLDPC.charConjValue_zero}
\leanok
\uses{def:char_conj_value}

For any character $\chi \in \hat{A}$, we have $\overline{\chi(0)} = 1$.
\end{theorem}

\begin{proof}
\leanok

By definition of the conjugate character value, $\overline{\chi(0)} = \mathrm{conj}(\chi(0))$. Since $\chi$ is a group homomorphism, $\chi(0) = 1$, and thus $\mathrm{conj}(1) = 1$.
\end{proof}

\begin{theorem}[Conjugate Preserves Multiplication]
\label{thm:char_conj_value_add}
\lean{GaugingLDPC.charConjValue_add}
\leanok
\uses{def:char_conj_value}

For any character $\chi \in \hat{A}$ and elements $g_1, g_2 \in A$,
\[
\overline{\chi(g_1 + g_2)} = \overline{\chi(g_1)} \cdot \overline{\chi(g_2)}.
\]
\end{theorem}

\begin{proof}
\leanok

By the definition of the conjugate character value, $\overline{\chi(g_1 + g_2)} = \mathrm{conj}(\chi(g_1 + g_2))$. Since $\chi$ is a character, $\chi(g_1 + g_2) = \chi(g_1) \cdot \chi(g_2)$. Thus $\mathrm{conj}(\chi(g_1) \cdot \chi(g_2)) = \mathrm{conj}(\chi(g_1)) \cdot \mathrm{conj}(\chi(g_2)) = \overline{\chi(g_1)} \cdot \overline{\chi(g_2)}$.
\end{proof}

\begin{theorem}[Conjugate Equals Negative Argument]
\label{thm:char_conj_value_eq_neg}
\lean{GaugingLDPC.charConjValue_eq_neg}
\leanok
\uses{def:char_conj_value}

For any character $\chi \in \hat{A}$ and element $g \in A$, we have
\[
\overline{\chi(g)} = \chi(-g).
\]
\end{theorem}

\begin{proof}
\leanok

By definition, $\overline{\chi(g)} = \mathrm{conj}(\chi(g))$. We first establish that $\chi(g) \cdot \chi(-g) = 1$ by noting that $\chi(g + (-g)) = \chi(0) = 1$ by the character property. Thus $\chi(-g) = \chi(g)^{-1}$.

Since $\chi(g)$ is a $p$-th root of unity (as $(\chi(g))^p = 1$), we have $\|\chi(g)\| = 1$. For complex numbers of modulus 1, the inverse equals the conjugate: $\chi(g)^{-1} = \mathrm{conj}(\chi(g))$. Therefore $\chi(-g) = \mathrm{conj}(\chi(g)) = \overline{\chi(g)}$.
\end{proof}

\begin{theorem}[Conjugate of Standard Character]
\label{thm:char_conj_value_standard_char}
\lean{GaugingLDPC.charConjValue_standardChar}
\leanok
\uses{def:char_conj_value, thm:char_conj_value_eq_neg}

For the standard character $\chi_k$ indexed by $k \in \mathbb{Z}_p$ and any $g \in \mathbb{Z}_p$,
\[
\overline{\chi_k(g)} = \chi_{-k}(g).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{thm:char_conj_value_eq_neg}

By the previous theorem, $\overline{\chi_k(g)} = \chi_k(-g)$. The standard character is given by $\chi_k(g) = \exp(2\pi i \cdot k \cdot g / p)$. Therefore:
\[
\chi_k(-g) = \exp\left(\frac{2\pi i \cdot k \cdot (-g)}{p}\right).
\]

Since $k \cdot (-g) = (-k) \cdot g$ in $\mathbb{Z}_p$, we have:
\[
\chi_k(-g) = \exp\left(\frac{2\pi i \cdot (-k) \cdot g}{p}\right) = \chi_{-k}(g).
\]

The proof uses periodicity of the exponential function: for natural numbers $a$, $\exp(2\pi i \cdot a / p) = \exp(2\pi i \cdot (a \bmod p) / p)$ since the exponential is periodic with period $2\pi i$.
\end{proof}

\begin{definition}[Charge Projection]
\label{def:single_site_charge_projection}
\lean{GaugingLDPC.chargeProjection}
\leanok
\uses{def:char_conj_value, rem:symmetry_action_and_abelian_group_structure}

Let $R$ be a $\mathbb{C}$-algebra with ring structure, and let $\sigma = (\varphi_g)_{g \in A}$ be a symmetry action on $R$. For an operator $O \in R$ and character $\chi \in \hat{A}$, the \textbf{charge-$\chi$ component} (or charge projection) of $O$ is defined as:
\[
\llbracket O \rrbracket_\chi := \frac{1}{|A|} \sum_{g \in A} \overline{\chi(g)} \, \varphi_g(O)
\]
where $|A| = p$ is the order of the group and $\overline{\chi(g)}$ denotes the complex conjugate of $\chi(g)$.
\end{definition}

\begin{definition}[Charge Projection by Index]
\label{def:charge_projection_by_index}
\lean{GaugingLDPC.chargeProjectionByIndex}
\leanok
\uses{def:single_site_charge_projection}

The \textbf{charge-$k$ component} using the $k$-th standard character $\chi_k$ is defined as:
\[
\llbracket O \rrbracket_k := \llbracket O \rrbracket_{\chi_k} = \frac{1}{p} \sum_{g=0}^{p-1} e^{-2\pi i k g / p} \, \varphi_g(O).
\]
\end{definition}

\begin{theorem}[Charge Projection is Additive]
\label{thm:charge_projection_add}
\lean{GaugingLDPC.chargeProjection_add}
\leanok
\uses{def:single_site_charge_projection}

For any character $\chi$ and operators $O_1, O_2 \in R$,
\[
\llbracket O_1 + O_2 \rrbracket_\chi = \llbracket O_1 \rrbracket_\chi + \llbracket O_2 \rrbracket_\chi.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:single_site_charge_projection}

Unfolding the definition of charge projection, we have:
\[
\llbracket O_1 + O_2 \rrbracket_\chi = \frac{1}{p} \sum_{g \in A} \overline{\chi(g)} \, \varphi_g(O_1 + O_2).
\]
Since $\varphi_g$ is a ring automorphism, $\varphi_g(O_1 + O_2) = \varphi_g(O_1) + \varphi_g(O_2)$. By linearity of scalar multiplication and distributivity of sums, this equals:
\[
\frac{1}{p} \sum_{g \in A} \overline{\chi(g)} \, \varphi_g(O_1) + \frac{1}{p} \sum_{g \in A} \overline{\chi(g)} \, \varphi_g(O_2) = \llbracket O_1 \rrbracket_\chi + \llbracket O_2 \rrbracket_\chi.
\]
\end{proof}

\begin{theorem}[Charge Projection with Trivial Character]
\label{thm:charge_projection_trivial_char}
\lean{GaugingLDPC.chargeProjection_trivialChar}
\leanok
\uses{def:single_site_charge_projection, def:char_conj_value}

For the trivial character $\chi = 1$ (where $1(g) = 1$ for all $g$), the charge projection gives the $G$-average:
\[
\llbracket O \rrbracket_1 = \frac{1}{p} \sum_{g \in A} \varphi_g(O).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:single_site_charge_projection, def:char_conj_value}

Unfolding the definitions of charge projection and conjugate character value, we have:
\[
\llbracket O \rrbracket_1 = \frac{1}{p} \sum_{g \in A} \overline{1(g)} \, \varphi_g(O).
\]
Since the trivial character satisfies $1(g) = 1$ for all $g$, its conjugate is also 1. Applying this to each term in the sum, we obtain:
\[
\llbracket O \rrbracket_1 = \frac{1}{p} \sum_{g \in A} 1 \cdot \varphi_g(O) = \frac{1}{p} \sum_{g \in A} \varphi_g(O).
\]
\end{proof}

\begin{theorem}[Charge Projection at Index Zero]
\label{thm:charge_projection_by_index_zero}
\lean{GaugingLDPC.chargeProjectionByIndex_zero}
\leanok
\uses{def:charge_projection_by_index, thm:charge_projection_trivial_char}

The charge-$0$ component equals the $G$-average:
\[
\llbracket O \rrbracket_0 = \frac{1}{p} \sum_{g \in A} \varphi_g(O).
\]
\end{theorem}

\begin{proof}
\leanok
\uses{thm:charge_projection_trivial_char}

Unfolding the definition of charge projection by index, $\llbracket O \rrbracket_0 = \llbracket O \rrbracket_{\chi_0}$. The standard character at index 0 is the trivial character: $\chi_0(g) = \exp(2\pi i \cdot 0 \cdot g / p) = 1$ for all $g$. Rewriting with this equality and applying the theorem for trivial characters, we obtain the result.
\end{proof}

\begin{theorem}[Charge Projection of Zero]
\label{thm:charge_projection_zero}
\lean{GaugingLDPC.chargeProjection_zero}
\leanok
\uses{def:single_site_charge_projection}

For any character $\chi$, the charge projection of zero is zero:
\[
\llbracket 0 \rrbracket_\chi = 0.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:single_site_charge_projection}

Unfolding the definition of charge projection:
\[
\llbracket 0 \rrbracket_\chi = \frac{1}{p} \sum_{g \in A} \overline{\chi(g)} \, \varphi_g(0).
\]
Since each $\varphi_g$ is a ring automorphism, $\varphi_g(0) = 0$. Thus each term $\overline{\chi(g)} \cdot 0 = 0$, and the sum of zeros is zero.
\end{proof}

\begin{theorem}[Charge Projection of Identity]
\label{thm:charge_projection_one}
\lean{GaugingLDPC.chargeProjection_one}
\leanok
\uses{def:single_site_charge_projection, def:char_conj_value}

For any character $\chi$, the charge projection of the identity operator is:
\[
\llbracket 1 \rrbracket_\chi = \frac{1}{p} \sum_{g \in A} \overline{\chi(g)} \cdot 1.
\]
\end{theorem}

\begin{proof}
\leanok
\uses{def:single_site_charge_projection}

Unfolding the definition of charge projection:
\[
\llbracket 1 \rrbracket_\chi = \frac{1}{p} \sum_{g \in A} \overline{\chi(g)} \, \varphi_g(1).
\]
For each $g$, we have $\varphi_g(1) = 1$ since $\varphi_g$ is a ring automorphism (and thus preserves the multiplicative identity). Applying this equality to each term in the sum, we obtain the stated result.
\end{proof}

\begin{theorem}[Character Sum Orthogonality]
\label{thm:character_sum_eq}
\lean{GaugingLDPC.character_sum_eq}
\leanok

For any character $\chi \in \hat{A}$,
\[
\sum_{g \in A} \chi(g) = \begin{cases} p & \text{if } \chi = 1 \\ 0 & \text{otherwise} \end{cases}
\]
\end{theorem}

\begin{proof}
\leanok

We split into two cases based on whether $\chi$ equals the trivial character.

\textbf{Case 1:} $\chi = 1$ (trivial character). By substitution, $\chi(g) = 1$ for all $g$. Thus:
\[
\sum_{g \in A} \chi(g) = \sum_{g \in A} 1 = |A| = p.
\]

\textbf{Case 2:} $\chi \neq 1$. Since $\chi$ is not trivial, there exists $g_0 \in A$ such that $\chi(g_0) \neq 1$. Let $S = \sum_{g \in A} \chi(g)$. By reindexing the sum via $g \mapsto g + g_0$:
\[
S = \sum_{g \in A} \chi(g) = \sum_{g \in A} \chi(g + g_0) = \sum_{g \in A} \chi(g) \chi(g_0) = \chi(g_0) \cdot S.
\]
The bijection $g \mapsto g + g_0$ is justified by adding $-g_0$ as the inverse. From $S = \chi(g_0) \cdot S$, we obtain $(1 - \chi(g_0)) \cdot S = 0$. Since $1 - \chi(g_0) \neq 0$ (as $\chi(g_0) \neq 1$), we conclude $S = 0$.
\end{proof}

\begin{theorem}[Conjugate Character Sum]
\label{thm:character_conj_sum_eq}
\lean{GaugingLDPC.character_conj_sum_eq}
\leanok
\uses{def:char_conj_value, thm:char_conj_value_eq_neg, thm:character_sum_eq}

For any character $\chi \in \hat{A}$,
\[
\sum_{g \in A} \overline{\chi(g)} = \begin{cases} p & \text{if } \chi = 1 \\ 0 & \text{otherwise} \end{cases}
\]
\end{theorem}

\begin{proof}
\leanok
\uses{thm:char_conj_value_eq_neg, thm:character_sum_eq}

For each $g$, by the theorem on conjugate equals negative argument, $\overline{\chi(g)} = \chi(-g)$. Substituting this identity:
\[
\sum_{g \in A} \overline{\chi(g)} = \sum_{g \in A} \chi(-g).
\]
By reindexing via the bijection $g \mapsto -g$ (with inverse $g \mapsto -g$),we have:
\[
\sum_{g \in A} \chi(-g) = \sum_{g \in A} \chi(g).
\]
By the character sum orthogonality theorem, this equals $p$ if $\chi = 1$ and $0$ otherwise.
\end{proof}

